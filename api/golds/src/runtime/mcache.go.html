<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Source: mcache.go in package runtime</title>
<link href="../../css/dark-v0.6.8.css" rel="stylesheet">
<script src="../../jvs/golds-v0.6.8.js"></script>
<body onload="onPageLoad()"><div>

<pre id="header"><code><span class="title">Source File</span>
	mcache.go

<span class="title">Belonging Package</span>
	<a href="../../pkg/runtime.html">runtime</a>
</code></pre>

<pre class="line-numbers">
<span class="codeline" id="line-1"><code>// Copyright 2009 The Go Authors. All rights reserved.</code></span>
<span class="codeline" id="line-2"><code>// Use of this source code is governed by a BSD-style</code></span>
<span class="codeline" id="line-3"><code>// license that can be found in the LICENSE file.</code></span>
<span class="codeline" id="line-4"><code></code></span>
<span class="codeline" id="line-5"><code>package runtime</code></span>
<span class="codeline" id="line-6"><code></code></span>
<span class="codeline" id="line-7"><code>import (</code></span>
<span class="codeline" id="line-8"><code>	"runtime/internal/atomic"</code></span>
<span class="codeline" id="line-9"><code>	"runtime/internal/sys"</code></span>
<span class="codeline" id="line-10"><code>	"unsafe"</code></span>
<span class="codeline" id="line-11"><code>)</code></span>
<span class="codeline" id="line-12"><code></code></span>
<span class="codeline" id="line-13"><code>// Per-thread (in Go, per-P) cache for small objects.</code></span>
<span class="codeline" id="line-14"><code>// This includes a small object cache and local allocation stats.</code></span>
<span class="codeline" id="line-15"><code>// No locking needed because it is per-thread (per-P).</code></span>
<span class="codeline" id="line-16"><code>//</code></span>
<span class="codeline" id="line-17"><code>// mcaches are allocated from non-GC'd memory, so any heap pointers</code></span>
<span class="codeline" id="line-18"><code>// must be specially handled.</code></span>
<span class="codeline" id="line-19"><code>type mcache struct {</code></span>
<span class="codeline" id="line-20"><code>	_ sys.NotInHeap</code></span>
<span class="codeline" id="line-21"><code></code></span>
<span class="codeline" id="line-22"><code>	// The following members are accessed on every malloc,</code></span>
<span class="codeline" id="line-23"><code>	// so they are grouped here for better caching.</code></span>
<span class="codeline" id="line-24"><code>	nextSample uintptr // trigger heap sample after allocating this many bytes</code></span>
<span class="codeline" id="line-25"><code>	scanAlloc  uintptr // bytes of scannable heap allocated</code></span>
<span class="codeline" id="line-26"><code></code></span>
<span class="codeline" id="line-27"><code>	// Allocator cache for tiny objects w/o pointers.</code></span>
<span class="codeline" id="line-28"><code>	// See "Tiny allocator" comment in malloc.go.</code></span>
<span class="codeline" id="line-29"><code></code></span>
<span class="codeline" id="line-30"><code>	// tiny points to the beginning of the current tiny block, or</code></span>
<span class="codeline" id="line-31"><code>	// nil if there is no current tiny block.</code></span>
<span class="codeline" id="line-32"><code>	//</code></span>
<span class="codeline" id="line-33"><code>	// tiny is a heap pointer. Since mcache is in non-GC'd memory,</code></span>
<span class="codeline" id="line-34"><code>	// we handle it by clearing it in releaseAll during mark</code></span>
<span class="codeline" id="line-35"><code>	// termination.</code></span>
<span class="codeline" id="line-36"><code>	//</code></span>
<span class="codeline" id="line-37"><code>	// tinyAllocs is the number of tiny allocations performed</code></span>
<span class="codeline" id="line-38"><code>	// by the P that owns this mcache.</code></span>
<span class="codeline" id="line-39"><code>	tiny       uintptr</code></span>
<span class="codeline" id="line-40"><code>	tinyoffset uintptr</code></span>
<span class="codeline" id="line-41"><code>	tinyAllocs uintptr</code></span>
<span class="codeline" id="line-42"><code></code></span>
<span class="codeline" id="line-43"><code>	// The rest is not accessed on every malloc.</code></span>
<span class="codeline" id="line-44"><code></code></span>
<span class="codeline" id="line-45"><code>	alloc [numSpanClasses]*mspan // spans to allocate from, indexed by spanClass</code></span>
<span class="codeline" id="line-46"><code></code></span>
<span class="codeline" id="line-47"><code>	stackcache [_NumStackOrders]stackfreelist</code></span>
<span class="codeline" id="line-48"><code></code></span>
<span class="codeline" id="line-49"><code>	// flushGen indicates the sweepgen during which this mcache</code></span>
<span class="codeline" id="line-50"><code>	// was last flushed. If flushGen != mheap_.sweepgen, the spans</code></span>
<span class="codeline" id="line-51"><code>	// in this mcache are stale and need to the flushed so they</code></span>
<span class="codeline" id="line-52"><code>	// can be swept. This is done in acquirep.</code></span>
<span class="codeline" id="line-53"><code>	flushGen atomic.Uint32</code></span>
<span class="codeline" id="line-54"><code>}</code></span>
<span class="codeline" id="line-55"><code></code></span>
<span class="codeline" id="line-56"><code>// A gclink is a node in a linked list of blocks, like mlink,</code></span>
<span class="codeline" id="line-57"><code>// but it is opaque to the garbage collector.</code></span>
<span class="codeline" id="line-58"><code>// The GC does not trace the pointers during collection,</code></span>
<span class="codeline" id="line-59"><code>// and the compiler does not emit write barriers for assignments</code></span>
<span class="codeline" id="line-60"><code>// of gclinkptr values. Code should store references to gclinks</code></span>
<span class="codeline" id="line-61"><code>// as gclinkptr, not as *gclink.</code></span>
<span class="codeline" id="line-62"><code>type gclink struct {</code></span>
<span class="codeline" id="line-63"><code>	next gclinkptr</code></span>
<span class="codeline" id="line-64"><code>}</code></span>
<span class="codeline" id="line-65"><code></code></span>
<span class="codeline" id="line-66"><code>// A gclinkptr is a pointer to a gclink, but it is opaque</code></span>
<span class="codeline" id="line-67"><code>// to the garbage collector.</code></span>
<span class="codeline" id="line-68"><code>type gclinkptr uintptr</code></span>
<span class="codeline" id="line-69"><code></code></span>
<span class="codeline" id="line-70"><code>// ptr returns the *gclink form of p.</code></span>
<span class="codeline" id="line-71"><code>// The result should be used for accessing fields, not stored</code></span>
<span class="codeline" id="line-72"><code>// in other data structures.</code></span>
<span class="codeline" id="line-73"><code>func (p gclinkptr) ptr() *gclink {</code></span>
<span class="codeline" id="line-74"><code>	return (*gclink)(unsafe.Pointer(p))</code></span>
<span class="codeline" id="line-75"><code>}</code></span>
<span class="codeline" id="line-76"><code></code></span>
<span class="codeline" id="line-77"><code>type stackfreelist struct {</code></span>
<span class="codeline" id="line-78"><code>	list gclinkptr // linked list of free stacks</code></span>
<span class="codeline" id="line-79"><code>	size uintptr   // total size of stacks in list</code></span>
<span class="codeline" id="line-80"><code>}</code></span>
<span class="codeline" id="line-81"><code></code></span>
<span class="codeline" id="line-82"><code>// dummy mspan that contains no free objects.</code></span>
<span class="codeline" id="line-83"><code>var emptymspan mspan</code></span>
<span class="codeline" id="line-84"><code></code></span>
<span class="codeline" id="line-85"><code>func allocmcache() *mcache {</code></span>
<span class="codeline" id="line-86"><code>	var c *mcache</code></span>
<span class="codeline" id="line-87"><code>	systemstack(func() {</code></span>
<span class="codeline" id="line-88"><code>		lock(&amp;mheap_.lock)</code></span>
<span class="codeline" id="line-89"><code>		c = (*mcache)(mheap_.cachealloc.alloc())</code></span>
<span class="codeline" id="line-90"><code>		c.flushGen.Store(mheap_.sweepgen)</code></span>
<span class="codeline" id="line-91"><code>		unlock(&amp;mheap_.lock)</code></span>
<span class="codeline" id="line-92"><code>	})</code></span>
<span class="codeline" id="line-93"><code>	for i := range c.alloc {</code></span>
<span class="codeline" id="line-94"><code>		c.alloc[i] = &amp;emptymspan</code></span>
<span class="codeline" id="line-95"><code>	}</code></span>
<span class="codeline" id="line-96"><code>	c.nextSample = nextSample()</code></span>
<span class="codeline" id="line-97"><code>	return c</code></span>
<span class="codeline" id="line-98"><code>}</code></span>
<span class="codeline" id="line-99"><code></code></span>
<span class="codeline" id="line-100"><code>// freemcache releases resources associated with this</code></span>
<span class="codeline" id="line-101"><code>// mcache and puts the object onto a free list.</code></span>
<span class="codeline" id="line-102"><code>//</code></span>
<span class="codeline" id="line-103"><code>// In some cases there is no way to simply release</code></span>
<span class="codeline" id="line-104"><code>// resources, such as statistics, so donate them to</code></span>
<span class="codeline" id="line-105"><code>// a different mcache (the recipient).</code></span>
<span class="codeline" id="line-106"><code>func freemcache(c *mcache) {</code></span>
<span class="codeline" id="line-107"><code>	systemstack(func() {</code></span>
<span class="codeline" id="line-108"><code>		c.releaseAll()</code></span>
<span class="codeline" id="line-109"><code>		stackcache_clear(c)</code></span>
<span class="codeline" id="line-110"><code></code></span>
<span class="codeline" id="line-111"><code>		// NOTE(rsc,rlh): If gcworkbuffree comes back, we need to coordinate</code></span>
<span class="codeline" id="line-112"><code>		// with the stealing of gcworkbufs during garbage collection to avoid</code></span>
<span class="codeline" id="line-113"><code>		// a race where the workbuf is double-freed.</code></span>
<span class="codeline" id="line-114"><code>		// gcworkbuffree(c.gcworkbuf)</code></span>
<span class="codeline" id="line-115"><code></code></span>
<span class="codeline" id="line-116"><code>		lock(&amp;mheap_.lock)</code></span>
<span class="codeline" id="line-117"><code>		mheap_.cachealloc.free(unsafe.Pointer(c))</code></span>
<span class="codeline" id="line-118"><code>		unlock(&amp;mheap_.lock)</code></span>
<span class="codeline" id="line-119"><code>	})</code></span>
<span class="codeline" id="line-120"><code>}</code></span>
<span class="codeline" id="line-121"><code></code></span>
<span class="codeline" id="line-122"><code>// getMCache is a convenience function which tries to obtain an mcache.</code></span>
<span class="codeline" id="line-123"><code>//</code></span>
<span class="codeline" id="line-124"><code>// Returns nil if we're not bootstrapping or we don't have a P. The caller's</code></span>
<span class="codeline" id="line-125"><code>// P must not change, so we must be in a non-preemptible state.</code></span>
<span class="codeline" id="line-126"><code>func getMCache(mp *m) *mcache {</code></span>
<span class="codeline" id="line-127"><code>	// Grab the mcache, since that's where stats live.</code></span>
<span class="codeline" id="line-128"><code>	pp := mp.p.ptr()</code></span>
<span class="codeline" id="line-129"><code>	var c *mcache</code></span>
<span class="codeline" id="line-130"><code>	if pp == nil {</code></span>
<span class="codeline" id="line-131"><code>		// We will be called without a P while bootstrapping,</code></span>
<span class="codeline" id="line-132"><code>		// in which case we use mcache0, which is set in mallocinit.</code></span>
<span class="codeline" id="line-133"><code>		// mcache0 is cleared when bootstrapping is complete,</code></span>
<span class="codeline" id="line-134"><code>		// by procresize.</code></span>
<span class="codeline" id="line-135"><code>		c = mcache0</code></span>
<span class="codeline" id="line-136"><code>	} else {</code></span>
<span class="codeline" id="line-137"><code>		c = pp.mcache</code></span>
<span class="codeline" id="line-138"><code>	}</code></span>
<span class="codeline" id="line-139"><code>	return c</code></span>
<span class="codeline" id="line-140"><code>}</code></span>
<span class="codeline" id="line-141"><code></code></span>
<span class="codeline" id="line-142"><code>// refill acquires a new span of span class spc for c. This span will</code></span>
<span class="codeline" id="line-143"><code>// have at least one free object. The current span in c must be full.</code></span>
<span class="codeline" id="line-144"><code>//</code></span>
<span class="codeline" id="line-145"><code>// Must run in a non-preemptible context since otherwise the owner of</code></span>
<span class="codeline" id="line-146"><code>// c could change.</code></span>
<span class="codeline" id="line-147"><code>func (c *mcache) refill(spc spanClass) {</code></span>
<span class="codeline" id="line-148"><code>	// Return the current cached span to the central lists.</code></span>
<span class="codeline" id="line-149"><code>	s := c.alloc[spc]</code></span>
<span class="codeline" id="line-150"><code></code></span>
<span class="codeline" id="line-151"><code>	if s.allocCount != s.nelems {</code></span>
<span class="codeline" id="line-152"><code>		throw("refill of span with free space remaining")</code></span>
<span class="codeline" id="line-153"><code>	}</code></span>
<span class="codeline" id="line-154"><code>	if s != &amp;emptymspan {</code></span>
<span class="codeline" id="line-155"><code>		// Mark this span as no longer cached.</code></span>
<span class="codeline" id="line-156"><code>		if s.sweepgen != mheap_.sweepgen+3 {</code></span>
<span class="codeline" id="line-157"><code>			throw("bad sweepgen in refill")</code></span>
<span class="codeline" id="line-158"><code>		}</code></span>
<span class="codeline" id="line-159"><code>		mheap_.central[spc].mcentral.uncacheSpan(s)</code></span>
<span class="codeline" id="line-160"><code></code></span>
<span class="codeline" id="line-161"><code>		// Count up how many slots were used and record it.</code></span>
<span class="codeline" id="line-162"><code>		stats := memstats.heapStats.acquire()</code></span>
<span class="codeline" id="line-163"><code>		slotsUsed := int64(s.allocCount) - int64(s.allocCountBeforeCache)</code></span>
<span class="codeline" id="line-164"><code>		atomic.Xadd64(&amp;stats.smallAllocCount[spc.sizeclass()], slotsUsed)</code></span>
<span class="codeline" id="line-165"><code></code></span>
<span class="codeline" id="line-166"><code>		// Flush tinyAllocs.</code></span>
<span class="codeline" id="line-167"><code>		if spc == tinySpanClass {</code></span>
<span class="codeline" id="line-168"><code>			atomic.Xadd64(&amp;stats.tinyAllocCount, int64(c.tinyAllocs))</code></span>
<span class="codeline" id="line-169"><code>			c.tinyAllocs = 0</code></span>
<span class="codeline" id="line-170"><code>		}</code></span>
<span class="codeline" id="line-171"><code>		memstats.heapStats.release()</code></span>
<span class="codeline" id="line-172"><code></code></span>
<span class="codeline" id="line-173"><code>		// Count the allocs in inconsistent, internal stats.</code></span>
<span class="codeline" id="line-174"><code>		bytesAllocated := slotsUsed * int64(s.elemsize)</code></span>
<span class="codeline" id="line-175"><code>		gcController.totalAlloc.Add(bytesAllocated)</code></span>
<span class="codeline" id="line-176"><code></code></span>
<span class="codeline" id="line-177"><code>		// Clear the second allocCount just to be safe.</code></span>
<span class="codeline" id="line-178"><code>		s.allocCountBeforeCache = 0</code></span>
<span class="codeline" id="line-179"><code>	}</code></span>
<span class="codeline" id="line-180"><code></code></span>
<span class="codeline" id="line-181"><code>	// Get a new cached span from the central lists.</code></span>
<span class="codeline" id="line-182"><code>	s = mheap_.central[spc].mcentral.cacheSpan()</code></span>
<span class="codeline" id="line-183"><code>	if s == nil {</code></span>
<span class="codeline" id="line-184"><code>		throw("out of memory")</code></span>
<span class="codeline" id="line-185"><code>	}</code></span>
<span class="codeline" id="line-186"><code></code></span>
<span class="codeline" id="line-187"><code>	if s.allocCount == s.nelems {</code></span>
<span class="codeline" id="line-188"><code>		throw("span has no free space")</code></span>
<span class="codeline" id="line-189"><code>	}</code></span>
<span class="codeline" id="line-190"><code></code></span>
<span class="codeline" id="line-191"><code>	// Indicate that this span is cached and prevent asynchronous</code></span>
<span class="codeline" id="line-192"><code>	// sweeping in the next sweep phase.</code></span>
<span class="codeline" id="line-193"><code>	s.sweepgen = mheap_.sweepgen + 3</code></span>
<span class="codeline" id="line-194"><code></code></span>
<span class="codeline" id="line-195"><code>	// Store the current alloc count for accounting later.</code></span>
<span class="codeline" id="line-196"><code>	s.allocCountBeforeCache = s.allocCount</code></span>
<span class="codeline" id="line-197"><code></code></span>
<span class="codeline" id="line-198"><code>	// Update heapLive and flush scanAlloc.</code></span>
<span class="codeline" id="line-199"><code>	//</code></span>
<span class="codeline" id="line-200"><code>	// We have not yet allocated anything new into the span, but we</code></span>
<span class="codeline" id="line-201"><code>	// assume that all of its slots will get used, so this makes</code></span>
<span class="codeline" id="line-202"><code>	// heapLive an overestimate.</code></span>
<span class="codeline" id="line-203"><code>	//</code></span>
<span class="codeline" id="line-204"><code>	// When the span gets uncached, we'll fix up this overestimate</code></span>
<span class="codeline" id="line-205"><code>	// if necessary (see releaseAll).</code></span>
<span class="codeline" id="line-206"><code>	//</code></span>
<span class="codeline" id="line-207"><code>	// We pick an overestimate here because an underestimate leads</code></span>
<span class="codeline" id="line-208"><code>	// the pacer to believe that it's in better shape than it is,</code></span>
<span class="codeline" id="line-209"><code>	// which appears to lead to more memory used. See #53738 for</code></span>
<span class="codeline" id="line-210"><code>	// more details.</code></span>
<span class="codeline" id="line-211"><code>	usedBytes := uintptr(s.allocCount) * s.elemsize</code></span>
<span class="codeline" id="line-212"><code>	gcController.update(int64(s.npages*pageSize)-int64(usedBytes), int64(c.scanAlloc))</code></span>
<span class="codeline" id="line-213"><code>	c.scanAlloc = 0</code></span>
<span class="codeline" id="line-214"><code></code></span>
<span class="codeline" id="line-215"><code>	c.alloc[spc] = s</code></span>
<span class="codeline" id="line-216"><code>}</code></span>
<span class="codeline" id="line-217"><code></code></span>
<span class="codeline" id="line-218"><code>// allocLarge allocates a span for a large object.</code></span>
<span class="codeline" id="line-219"><code>func (c *mcache) allocLarge(size uintptr, noscan bool) *mspan {</code></span>
<span class="codeline" id="line-220"><code>	if size+_PageSize &lt; size {</code></span>
<span class="codeline" id="line-221"><code>		throw("out of memory")</code></span>
<span class="codeline" id="line-222"><code>	}</code></span>
<span class="codeline" id="line-223"><code>	npages := size &gt;&gt; _PageShift</code></span>
<span class="codeline" id="line-224"><code>	if size&amp;_PageMask != 0 {</code></span>
<span class="codeline" id="line-225"><code>		npages++</code></span>
<span class="codeline" id="line-226"><code>	}</code></span>
<span class="codeline" id="line-227"><code></code></span>
<span class="codeline" id="line-228"><code>	// Deduct credit for this span allocation and sweep if</code></span>
<span class="codeline" id="line-229"><code>	// necessary. mHeap_Alloc will also sweep npages, so this only</code></span>
<span class="codeline" id="line-230"><code>	// pays the debt down to npage pages.</code></span>
<span class="codeline" id="line-231"><code>	deductSweepCredit(npages*_PageSize, npages)</code></span>
<span class="codeline" id="line-232"><code></code></span>
<span class="codeline" id="line-233"><code>	spc := makeSpanClass(0, noscan)</code></span>
<span class="codeline" id="line-234"><code>	s := mheap_.alloc(npages, spc)</code></span>
<span class="codeline" id="line-235"><code>	if s == nil {</code></span>
<span class="codeline" id="line-236"><code>		throw("out of memory")</code></span>
<span class="codeline" id="line-237"><code>	}</code></span>
<span class="codeline" id="line-238"><code></code></span>
<span class="codeline" id="line-239"><code>	// Count the alloc in consistent, external stats.</code></span>
<span class="codeline" id="line-240"><code>	stats := memstats.heapStats.acquire()</code></span>
<span class="codeline" id="line-241"><code>	atomic.Xadd64(&amp;stats.largeAlloc, int64(npages*pageSize))</code></span>
<span class="codeline" id="line-242"><code>	atomic.Xadd64(&amp;stats.largeAllocCount, 1)</code></span>
<span class="codeline" id="line-243"><code>	memstats.heapStats.release()</code></span>
<span class="codeline" id="line-244"><code></code></span>
<span class="codeline" id="line-245"><code>	// Count the alloc in inconsistent, internal stats.</code></span>
<span class="codeline" id="line-246"><code>	gcController.totalAlloc.Add(int64(npages * pageSize))</code></span>
<span class="codeline" id="line-247"><code></code></span>
<span class="codeline" id="line-248"><code>	// Update heapLive.</code></span>
<span class="codeline" id="line-249"><code>	gcController.update(int64(s.npages*pageSize), 0)</code></span>
<span class="codeline" id="line-250"><code></code></span>
<span class="codeline" id="line-251"><code>	// Put the large span in the mcentral swept list so that it's</code></span>
<span class="codeline" id="line-252"><code>	// visible to the background sweeper.</code></span>
<span class="codeline" id="line-253"><code>	mheap_.central[spc].mcentral.fullSwept(mheap_.sweepgen).push(s)</code></span>
<span class="codeline" id="line-254"><code>	s.limit = s.base() + size</code></span>
<span class="codeline" id="line-255"><code>	s.initHeapBits(false)</code></span>
<span class="codeline" id="line-256"><code>	return s</code></span>
<span class="codeline" id="line-257"><code>}</code></span>
<span class="codeline" id="line-258"><code></code></span>
<span class="codeline" id="line-259"><code>func (c *mcache) releaseAll() {</code></span>
<span class="codeline" id="line-260"><code>	// Take this opportunity to flush scanAlloc.</code></span>
<span class="codeline" id="line-261"><code>	scanAlloc := int64(c.scanAlloc)</code></span>
<span class="codeline" id="line-262"><code>	c.scanAlloc = 0</code></span>
<span class="codeline" id="line-263"><code></code></span>
<span class="codeline" id="line-264"><code>	sg := mheap_.sweepgen</code></span>
<span class="codeline" id="line-265"><code>	dHeapLive := int64(0)</code></span>
<span class="codeline" id="line-266"><code>	for i := range c.alloc {</code></span>
<span class="codeline" id="line-267"><code>		s := c.alloc[i]</code></span>
<span class="codeline" id="line-268"><code>		if s != &amp;emptymspan {</code></span>
<span class="codeline" id="line-269"><code>			slotsUsed := int64(s.allocCount) - int64(s.allocCountBeforeCache)</code></span>
<span class="codeline" id="line-270"><code>			s.allocCountBeforeCache = 0</code></span>
<span class="codeline" id="line-271"><code></code></span>
<span class="codeline" id="line-272"><code>			// Adjust smallAllocCount for whatever was allocated.</code></span>
<span class="codeline" id="line-273"><code>			stats := memstats.heapStats.acquire()</code></span>
<span class="codeline" id="line-274"><code>			atomic.Xadd64(&amp;stats.smallAllocCount[spanClass(i).sizeclass()], slotsUsed)</code></span>
<span class="codeline" id="line-275"><code>			memstats.heapStats.release()</code></span>
<span class="codeline" id="line-276"><code></code></span>
<span class="codeline" id="line-277"><code>			// Adjust the actual allocs in inconsistent, internal stats.</code></span>
<span class="codeline" id="line-278"><code>			// We assumed earlier that the full span gets allocated.</code></span>
<span class="codeline" id="line-279"><code>			gcController.totalAlloc.Add(slotsUsed * int64(s.elemsize))</code></span>
<span class="codeline" id="line-280"><code></code></span>
<span class="codeline" id="line-281"><code>			if s.sweepgen != sg+1 {</code></span>
<span class="codeline" id="line-282"><code>				// refill conservatively counted unallocated slots in gcController.heapLive.</code></span>
<span class="codeline" id="line-283"><code>				// Undo this.</code></span>
<span class="codeline" id="line-284"><code>				//</code></span>
<span class="codeline" id="line-285"><code>				// If this span was cached before sweep, then gcController.heapLive was totally</code></span>
<span class="codeline" id="line-286"><code>				// recomputed since caching this span, so we don't do this for stale spans.</code></span>
<span class="codeline" id="line-287"><code>				dHeapLive -= int64(s.nelems-s.allocCount) * int64(s.elemsize)</code></span>
<span class="codeline" id="line-288"><code>			}</code></span>
<span class="codeline" id="line-289"><code></code></span>
<span class="codeline" id="line-290"><code>			// Release the span to the mcentral.</code></span>
<span class="codeline" id="line-291"><code>			mheap_.central[i].mcentral.uncacheSpan(s)</code></span>
<span class="codeline" id="line-292"><code>			c.alloc[i] = &amp;emptymspan</code></span>
<span class="codeline" id="line-293"><code>		}</code></span>
<span class="codeline" id="line-294"><code>	}</code></span>
<span class="codeline" id="line-295"><code>	// Clear tinyalloc pool.</code></span>
<span class="codeline" id="line-296"><code>	c.tiny = 0</code></span>
<span class="codeline" id="line-297"><code>	c.tinyoffset = 0</code></span>
<span class="codeline" id="line-298"><code></code></span>
<span class="codeline" id="line-299"><code>	// Flush tinyAllocs.</code></span>
<span class="codeline" id="line-300"><code>	stats := memstats.heapStats.acquire()</code></span>
<span class="codeline" id="line-301"><code>	atomic.Xadd64(&amp;stats.tinyAllocCount, int64(c.tinyAllocs))</code></span>
<span class="codeline" id="line-302"><code>	c.tinyAllocs = 0</code></span>
<span class="codeline" id="line-303"><code>	memstats.heapStats.release()</code></span>
<span class="codeline" id="line-304"><code></code></span>
<span class="codeline" id="line-305"><code>	// Update heapLive and heapScan.</code></span>
<span class="codeline" id="line-306"><code>	gcController.update(dHeapLive, scanAlloc)</code></span>
<span class="codeline" id="line-307"><code>}</code></span>
<span class="codeline" id="line-308"><code></code></span>
<span class="codeline" id="line-309"><code>// prepareForSweep flushes c if the system has entered a new sweep phase</code></span>
<span class="codeline" id="line-310"><code>// since c was populated. This must happen between the sweep phase</code></span>
<span class="codeline" id="line-311"><code>// starting and the first allocation from c.</code></span>
<span class="codeline" id="line-312"><code>func (c *mcache) prepareForSweep() {</code></span>
<span class="codeline" id="line-313"><code>	// Alternatively, instead of making sure we do this on every P</code></span>
<span class="codeline" id="line-314"><code>	// between starting the world and allocating on that P, we</code></span>
<span class="codeline" id="line-315"><code>	// could leave allocate-black on, allow allocation to continue</code></span>
<span class="codeline" id="line-316"><code>	// as usual, use a ragged barrier at the beginning of sweep to</code></span>
<span class="codeline" id="line-317"><code>	// ensure all cached spans are swept, and then disable</code></span>
<span class="codeline" id="line-318"><code>	// allocate-black. However, with this approach it's difficult</code></span>
<span class="codeline" id="line-319"><code>	// to avoid spilling mark bits into the *next* GC cycle.</code></span>
<span class="codeline" id="line-320"><code>	sg := mheap_.sweepgen</code></span>
<span class="codeline" id="line-321"><code>	flushGen := c.flushGen.Load()</code></span>
<span class="codeline" id="line-322"><code>	if flushGen == sg {</code></span>
<span class="codeline" id="line-323"><code>		return</code></span>
<span class="codeline" id="line-324"><code>	} else if flushGen != sg-2 {</code></span>
<span class="codeline" id="line-325"><code>		println("bad flushGen", flushGen, "in prepareForSweep; sweepgen", sg)</code></span>
<span class="codeline" id="line-326"><code>		throw("bad flushGen")</code></span>
<span class="codeline" id="line-327"><code>	}</code></span>
<span class="codeline" id="line-328"><code>	c.releaseAll()</code></span>
<span class="codeline" id="line-329"><code>	stackcache_clear(c)</code></span>
<span class="codeline" id="line-330"><code>	c.flushGen.Store(mheap_.sweepgen) // Synchronizes with gcStart</code></span>
<span class="codeline" id="line-331"><code>}</code></span>
</pre><pre id="footer">
<table><tr><td><img src="../../png/go101-twitter.png"></td>
<td>The pages are generated with <a href="https://go101.org/apps-and-libs/golds.html"><b>Golds</b></a> <i>v0.6.8</i>. (GOOS=linux GOARCH=amd64)
<b>Golds</b> is a <a href="https://go101.org">Go 101</a> project developed by <a href="https://tapirgames.com">Tapir Liu</a>.
PR and bug reports are welcome and can be submitted to <a href="https://github.com/go101/golds">the issue list</a>.
Please follow <a href="https://twitter.com/go100and1">@Go100and1</a> (reachable from the left QR code) to get the latest news of <b>Golds</b>.</td></tr></table></pre>