<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Source: mbitmap_allocheaders.go in package runtime</title>
<link href="../../css/dark-v0.6.8.css" rel="stylesheet">
<script src="../../jvs/golds-v0.6.8.js"></script>
<body onload="onPageLoad()"><div>

<pre id="header"><code><span class="title">Source File</span>
	mbitmap_allocheaders.go

<span class="title">Belonging Package</span>
	<a href="../../pkg/runtime.html">runtime</a>
</code></pre>

<pre class="line-numbers">
<span class="codeline" id="line-1"><code>// Copyright 2023 The Go Authors. All rights reserved.</code></span>
<span class="codeline" id="line-2"><code>// Use of this source code is governed by a BSD-style</code></span>
<span class="codeline" id="line-3"><code>// license that can be found in the LICENSE file.</code></span>
<span class="codeline" id="line-4"><code></code></span>
<span class="codeline" id="line-5"><code>//go:build goexperiment.allocheaders</code></span>
<span class="codeline" id="line-6"><code></code></span>
<span class="codeline" id="line-7"><code>// Garbage collector: type and heap bitmaps.</code></span>
<span class="codeline" id="line-8"><code>//</code></span>
<span class="codeline" id="line-9"><code>// Stack, data, and bss bitmaps</code></span>
<span class="codeline" id="line-10"><code>//</code></span>
<span class="codeline" id="line-11"><code>// Stack frames and global variables in the data and bss sections are</code></span>
<span class="codeline" id="line-12"><code>// described by bitmaps with 1 bit per pointer-sized word. A "1" bit</code></span>
<span class="codeline" id="line-13"><code>// means the word is a live pointer to be visited by the GC (referred to</code></span>
<span class="codeline" id="line-14"><code>// as "pointer"). A "0" bit means the word should be ignored by GC</code></span>
<span class="codeline" id="line-15"><code>// (referred to as "scalar", though it could be a dead pointer value).</code></span>
<span class="codeline" id="line-16"><code>//</code></span>
<span class="codeline" id="line-17"><code>// Heap bitmaps</code></span>
<span class="codeline" id="line-18"><code>//</code></span>
<span class="codeline" id="line-19"><code>// The heap bitmap comprises 1 bit for each pointer-sized word in the heap,</code></span>
<span class="codeline" id="line-20"><code>// recording whether a pointer is stored in that word or not. This bitmap</code></span>
<span class="codeline" id="line-21"><code>// is stored at the end of a span for small objects and is unrolled at</code></span>
<span class="codeline" id="line-22"><code>// runtime from type metadata for all larger objects. Objects without</code></span>
<span class="codeline" id="line-23"><code>// pointers have neither a bitmap nor associated type metadata.</code></span>
<span class="codeline" id="line-24"><code>//</code></span>
<span class="codeline" id="line-25"><code>// Bits in all cases correspond to words in little-endian order.</code></span>
<span class="codeline" id="line-26"><code>//</code></span>
<span class="codeline" id="line-27"><code>// For small objects, if s is the mspan for the span starting at "start",</code></span>
<span class="codeline" id="line-28"><code>// then s.heapBits() returns a slice containing the bitmap for the whole span.</code></span>
<span class="codeline" id="line-29"><code>// That is, s.heapBits()[0] holds the goarch.PtrSize*8 bits for the first</code></span>
<span class="codeline" id="line-30"><code>// goarch.PtrSize*8 words from "start" through "start+63*ptrSize" in the span.</code></span>
<span class="codeline" id="line-31"><code>// On a related note, small objects are always small enough that their bitmap</code></span>
<span class="codeline" id="line-32"><code>// fits in goarch.PtrSize*8 bits, so writing out bitmap data takes two bitmap</code></span>
<span class="codeline" id="line-33"><code>// writes at most (because object boundaries don't generally lie on</code></span>
<span class="codeline" id="line-34"><code>// s.heapBits()[i] boundaries).</code></span>
<span class="codeline" id="line-35"><code>//</code></span>
<span class="codeline" id="line-36"><code>// For larger objects, if t is the type for the object starting at "start",</code></span>
<span class="codeline" id="line-37"><code>// within some span whose mspan is s, then the bitmap at t.GCData is "tiled"</code></span>
<span class="codeline" id="line-38"><code>// from "start" through "start+s.elemsize".</code></span>
<span class="codeline" id="line-39"><code>// Specifically, the first bit of t.GCData corresponds to the word at "start",</code></span>
<span class="codeline" id="line-40"><code>// the second to the word after "start", and so on up to t.PtrBytes. At t.PtrBytes,</code></span>
<span class="codeline" id="line-41"><code>// we skip to "start+t.Size_" and begin again from there. This process is</code></span>
<span class="codeline" id="line-42"><code>// repeated until we hit "start+s.elemsize".</code></span>
<span class="codeline" id="line-43"><code>// This tiling algorithm supports array data, since the type always refers to</code></span>
<span class="codeline" id="line-44"><code>// the element type of the array. Single objects are considered the same as</code></span>
<span class="codeline" id="line-45"><code>// single-element arrays.</code></span>
<span class="codeline" id="line-46"><code>// The tiling algorithm may scan data past the end of the compiler-recognized</code></span>
<span class="codeline" id="line-47"><code>// object, but any unused data within the allocation slot (i.e. within s.elemsize)</code></span>
<span class="codeline" id="line-48"><code>// is zeroed, so the GC just observes nil pointers.</code></span>
<span class="codeline" id="line-49"><code>// Note that this "tiled" bitmap isn't stored anywhere; it is generated on-the-fly.</code></span>
<span class="codeline" id="line-50"><code>//</code></span>
<span class="codeline" id="line-51"><code>// For objects without their own span, the type metadata is stored in the first</code></span>
<span class="codeline" id="line-52"><code>// word before the object at the beginning of the allocation slot. For objects</code></span>
<span class="codeline" id="line-53"><code>// with their own span, the type metadata is stored in the mspan.</code></span>
<span class="codeline" id="line-54"><code>//</code></span>
<span class="codeline" id="line-55"><code>// The bitmap for small unallocated objects in scannable spans is not maintained</code></span>
<span class="codeline" id="line-56"><code>// (can be junk).</code></span>
<span class="codeline" id="line-57"><code></code></span>
<span class="codeline" id="line-58"><code>package runtime</code></span>
<span class="codeline" id="line-59"><code></code></span>
<span class="codeline" id="line-60"><code>import (</code></span>
<span class="codeline" id="line-61"><code>	"internal/abi"</code></span>
<span class="codeline" id="line-62"><code>	"internal/goarch"</code></span>
<span class="codeline" id="line-63"><code>	"runtime/internal/sys"</code></span>
<span class="codeline" id="line-64"><code>	"unsafe"</code></span>
<span class="codeline" id="line-65"><code>)</code></span>
<span class="codeline" id="line-66"><code></code></span>
<span class="codeline" id="line-67"><code>const (</code></span>
<span class="codeline" id="line-68"><code>	// A malloc header is functionally a single type pointer, but</code></span>
<span class="codeline" id="line-69"><code>	// we need to use 8 here to ensure 8-byte alignment of allocations</code></span>
<span class="codeline" id="line-70"><code>	// on 32-bit platforms. It's wasteful, but a lot of code relies on</code></span>
<span class="codeline" id="line-71"><code>	// 8-byte alignment for 8-byte atomics.</code></span>
<span class="codeline" id="line-72"><code>	mallocHeaderSize = 8</code></span>
<span class="codeline" id="line-73"><code></code></span>
<span class="codeline" id="line-74"><code>	// The minimum object size that has a malloc header, exclusive.</code></span>
<span class="codeline" id="line-75"><code>	//</code></span>
<span class="codeline" id="line-76"><code>	// The size of this value controls overheads from the malloc header.</code></span>
<span class="codeline" id="line-77"><code>	// The minimum size is bound by writeHeapBitsSmall, which assumes that the</code></span>
<span class="codeline" id="line-78"><code>	// pointer bitmap for objects of a size smaller than this doesn't cross</code></span>
<span class="codeline" id="line-79"><code>	// more than one pointer-word boundary. This sets an upper-bound on this</code></span>
<span class="codeline" id="line-80"><code>	// value at the number of bits in a uintptr, multiplied by the pointer</code></span>
<span class="codeline" id="line-81"><code>	// size in bytes.</code></span>
<span class="codeline" id="line-82"><code>	//</code></span>
<span class="codeline" id="line-83"><code>	// We choose a value here that has a natural cutover point in terms of memory</code></span>
<span class="codeline" id="line-84"><code>	// overheads. This value just happens to be the maximum possible value this</code></span>
<span class="codeline" id="line-85"><code>	// can be.</code></span>
<span class="codeline" id="line-86"><code>	//</code></span>
<span class="codeline" id="line-87"><code>	// A span with heap bits in it will have 128 bytes of heap bits on 64-bit</code></span>
<span class="codeline" id="line-88"><code>	// platforms, and 256 bytes of heap bits on 32-bit platforms. The first size</code></span>
<span class="codeline" id="line-89"><code>	// class where malloc headers match this overhead for 64-bit platforms is</code></span>
<span class="codeline" id="line-90"><code>	// 512 bytes (8 KiB / 512 bytes * 8 bytes-per-header = 128 bytes of overhead).</code></span>
<span class="codeline" id="line-91"><code>	// On 32-bit platforms, this same point is the 256 byte size class</code></span>
<span class="codeline" id="line-92"><code>	// (8 KiB / 256 bytes * 8 bytes-per-header = 256 bytes of overhead).</code></span>
<span class="codeline" id="line-93"><code>	//</code></span>
<span class="codeline" id="line-94"><code>	// Guaranteed to be exactly at a size class boundary. The reason this value is</code></span>
<span class="codeline" id="line-95"><code>	// an exclusive minimum is subtle. Suppose we're allocating a 504-byte object</code></span>
<span class="codeline" id="line-96"><code>	// and its rounded up to 512 bytes for the size class. If minSizeForMallocHeader</code></span>
<span class="codeline" id="line-97"><code>	// is 512 and an inclusive minimum, then a comparison against minSizeForMallocHeader</code></span>
<span class="codeline" id="line-98"><code>	// by the two values would produce different results. In other words, the comparison</code></span>
<span class="codeline" id="line-99"><code>	// would not be invariant to size-class rounding. Eschewing this property means a</code></span>
<span class="codeline" id="line-100"><code>	// more complex check or possibly storing additional state to determine whether a</code></span>
<span class="codeline" id="line-101"><code>	// span has malloc headers.</code></span>
<span class="codeline" id="line-102"><code>	minSizeForMallocHeader = goarch.PtrSize * ptrBits</code></span>
<span class="codeline" id="line-103"><code>)</code></span>
<span class="codeline" id="line-104"><code></code></span>
<span class="codeline" id="line-105"><code>// heapBitsInSpan returns true if the size of an object implies its ptr/scalar</code></span>
<span class="codeline" id="line-106"><code>// data is stored at the end of the span, and is accessible via span.heapBits.</code></span>
<span class="codeline" id="line-107"><code>//</code></span>
<span class="codeline" id="line-108"><code>// Note: this works for both rounded-up sizes (span.elemsize) and unrounded</code></span>
<span class="codeline" id="line-109"><code>// type sizes because minSizeForMallocHeader is guaranteed to be at a size</code></span>
<span class="codeline" id="line-110"><code>// class boundary.</code></span>
<span class="codeline" id="line-111"><code>//</code></span>
<span class="codeline" id="line-112"><code>//go:nosplit</code></span>
<span class="codeline" id="line-113"><code>func heapBitsInSpan(userSize uintptr) bool {</code></span>
<span class="codeline" id="line-114"><code>	// N.B. minSizeForMallocHeader is an exclusive minimum so that this function is</code></span>
<span class="codeline" id="line-115"><code>	// invariant under size-class rounding on its input.</code></span>
<span class="codeline" id="line-116"><code>	return userSize &lt;= minSizeForMallocHeader</code></span>
<span class="codeline" id="line-117"><code>}</code></span>
<span class="codeline" id="line-118"><code></code></span>
<span class="codeline" id="line-119"><code>// heapArenaPtrScalar contains the per-heapArena pointer/scalar metadata for the GC.</code></span>
<span class="codeline" id="line-120"><code>type heapArenaPtrScalar struct {</code></span>
<span class="codeline" id="line-121"><code>	// N.B. This is no longer necessary with allocation headers.</code></span>
<span class="codeline" id="line-122"><code>}</code></span>
<span class="codeline" id="line-123"><code></code></span>
<span class="codeline" id="line-124"><code>// typePointers is an iterator over the pointers in a heap object.</code></span>
<span class="codeline" id="line-125"><code>//</code></span>
<span class="codeline" id="line-126"><code>// Iteration through this type implements the tiling algorithm described at the</code></span>
<span class="codeline" id="line-127"><code>// top of this file.</code></span>
<span class="codeline" id="line-128"><code>type typePointers struct {</code></span>
<span class="codeline" id="line-129"><code>	// elem is the address of the current array element of type typ being iterated over.</code></span>
<span class="codeline" id="line-130"><code>	// Objects that are not arrays are treated as single-element arrays, in which case</code></span>
<span class="codeline" id="line-131"><code>	// this value does not change.</code></span>
<span class="codeline" id="line-132"><code>	elem uintptr</code></span>
<span class="codeline" id="line-133"><code></code></span>
<span class="codeline" id="line-134"><code>	// addr is the address the iterator is currently working from and describes</code></span>
<span class="codeline" id="line-135"><code>	// the address of the first word referenced by mask.</code></span>
<span class="codeline" id="line-136"><code>	addr uintptr</code></span>
<span class="codeline" id="line-137"><code></code></span>
<span class="codeline" id="line-138"><code>	// mask is a bitmask where each bit corresponds to pointer-words after addr.</code></span>
<span class="codeline" id="line-139"><code>	// Bit 0 is the pointer-word at addr, Bit 1 is the next word, and so on.</code></span>
<span class="codeline" id="line-140"><code>	// If a bit is 1, then there is a pointer at that word.</code></span>
<span class="codeline" id="line-141"><code>	// nextFast and next mask out bits in this mask as their pointers are processed.</code></span>
<span class="codeline" id="line-142"><code>	mask uintptr</code></span>
<span class="codeline" id="line-143"><code></code></span>
<span class="codeline" id="line-144"><code>	// typ is a pointer to the type information for the heap object's type.</code></span>
<span class="codeline" id="line-145"><code>	// This may be nil if the object is in a span where heapBitsInSpan(span.elemsize) is true.</code></span>
<span class="codeline" id="line-146"><code>	typ *_type</code></span>
<span class="codeline" id="line-147"><code>}</code></span>
<span class="codeline" id="line-148"><code></code></span>
<span class="codeline" id="line-149"><code>// typePointersOf returns an iterator over all heap pointers in the range [addr, addr+size).</code></span>
<span class="codeline" id="line-150"><code>//</code></span>
<span class="codeline" id="line-151"><code>// addr and addr+size must be in the range [span.base(), span.limit).</code></span>
<span class="codeline" id="line-152"><code>//</code></span>
<span class="codeline" id="line-153"><code>// Note: addr+size must be passed as the limit argument to the iterator's next method on</code></span>
<span class="codeline" id="line-154"><code>// each iteration. This slightly awkward API is to allow typePointers to be destructured</code></span>
<span class="codeline" id="line-155"><code>// by the compiler.</code></span>
<span class="codeline" id="line-156"><code>//</code></span>
<span class="codeline" id="line-157"><code>// nosplit because it is used during write barriers and must not be preempted.</code></span>
<span class="codeline" id="line-158"><code>//</code></span>
<span class="codeline" id="line-159"><code>//go:nosplit</code></span>
<span class="codeline" id="line-160"><code>func (span *mspan) typePointersOf(addr, size uintptr) typePointers {</code></span>
<span class="codeline" id="line-161"><code>	base := span.objBase(addr)</code></span>
<span class="codeline" id="line-162"><code>	tp := span.typePointersOfUnchecked(base)</code></span>
<span class="codeline" id="line-163"><code>	if base == addr &amp;&amp; size == span.elemsize {</code></span>
<span class="codeline" id="line-164"><code>		return tp</code></span>
<span class="codeline" id="line-165"><code>	}</code></span>
<span class="codeline" id="line-166"><code>	return tp.fastForward(addr-tp.addr, addr+size)</code></span>
<span class="codeline" id="line-167"><code>}</code></span>
<span class="codeline" id="line-168"><code></code></span>
<span class="codeline" id="line-169"><code>// typePointersOfUnchecked is like typePointersOf, but assumes addr is the base</code></span>
<span class="codeline" id="line-170"><code>// of an allocation slot in a span (the start of the object if no header, the</code></span>
<span class="codeline" id="line-171"><code>// header otherwise). It returns an iterator that generates all pointers</code></span>
<span class="codeline" id="line-172"><code>// in the range [addr, addr+span.elemsize).</code></span>
<span class="codeline" id="line-173"><code>//</code></span>
<span class="codeline" id="line-174"><code>// nosplit because it is used during write barriers and must not be preempted.</code></span>
<span class="codeline" id="line-175"><code>//</code></span>
<span class="codeline" id="line-176"><code>//go:nosplit</code></span>
<span class="codeline" id="line-177"><code>func (span *mspan) typePointersOfUnchecked(addr uintptr) typePointers {</code></span>
<span class="codeline" id="line-178"><code>	const doubleCheck = false</code></span>
<span class="codeline" id="line-179"><code>	if doubleCheck &amp;&amp; span.objBase(addr) != addr {</code></span>
<span class="codeline" id="line-180"><code>		print("runtime: addr=", addr, " base=", span.objBase(addr), "\n")</code></span>
<span class="codeline" id="line-181"><code>		throw("typePointersOfUnchecked consisting of non-base-address for object")</code></span>
<span class="codeline" id="line-182"><code>	}</code></span>
<span class="codeline" id="line-183"><code></code></span>
<span class="codeline" id="line-184"><code>	spc := span.spanclass</code></span>
<span class="codeline" id="line-185"><code>	if spc.noscan() {</code></span>
<span class="codeline" id="line-186"><code>		return typePointers{}</code></span>
<span class="codeline" id="line-187"><code>	}</code></span>
<span class="codeline" id="line-188"><code>	if heapBitsInSpan(span.elemsize) {</code></span>
<span class="codeline" id="line-189"><code>		// Handle header-less objects.</code></span>
<span class="codeline" id="line-190"><code>		return typePointers{elem: addr, addr: addr, mask: span.heapBitsSmallForAddr(addr)}</code></span>
<span class="codeline" id="line-191"><code>	}</code></span>
<span class="codeline" id="line-192"><code></code></span>
<span class="codeline" id="line-193"><code>	// All of these objects have a header.</code></span>
<span class="codeline" id="line-194"><code>	var typ *_type</code></span>
<span class="codeline" id="line-195"><code>	if spc.sizeclass() != 0 {</code></span>
<span class="codeline" id="line-196"><code>		// Pull the allocation header from the first word of the object.</code></span>
<span class="codeline" id="line-197"><code>		typ = *(**_type)(unsafe.Pointer(addr))</code></span>
<span class="codeline" id="line-198"><code>		addr += mallocHeaderSize</code></span>
<span class="codeline" id="line-199"><code>	} else {</code></span>
<span class="codeline" id="line-200"><code>		typ = span.largeType</code></span>
<span class="codeline" id="line-201"><code>	}</code></span>
<span class="codeline" id="line-202"><code>	gcdata := typ.GCData</code></span>
<span class="codeline" id="line-203"><code>	return typePointers{elem: addr, addr: addr, mask: readUintptr(gcdata), typ: typ}</code></span>
<span class="codeline" id="line-204"><code>}</code></span>
<span class="codeline" id="line-205"><code></code></span>
<span class="codeline" id="line-206"><code>// typePointersOfType is like typePointersOf, but assumes addr points to one or more</code></span>
<span class="codeline" id="line-207"><code>// contiguous instances of the provided type. The provided type must not be nil and</code></span>
<span class="codeline" id="line-208"><code>// it must not have its type metadata encoded as a gcprog.</code></span>
<span class="codeline" id="line-209"><code>//</code></span>
<span class="codeline" id="line-210"><code>// It returns an iterator that tiles typ.GCData starting from addr. It's the caller's</code></span>
<span class="codeline" id="line-211"><code>// responsibility to limit iteration.</code></span>
<span class="codeline" id="line-212"><code>//</code></span>
<span class="codeline" id="line-213"><code>// nosplit because its callers are nosplit and require all their callees to be nosplit.</code></span>
<span class="codeline" id="line-214"><code>//</code></span>
<span class="codeline" id="line-215"><code>//go:nosplit</code></span>
<span class="codeline" id="line-216"><code>func (span *mspan) typePointersOfType(typ *abi.Type, addr uintptr) typePointers {</code></span>
<span class="codeline" id="line-217"><code>	const doubleCheck = false</code></span>
<span class="codeline" id="line-218"><code>	if doubleCheck &amp;&amp; (typ == nil || typ.Kind_&amp;kindGCProg != 0) {</code></span>
<span class="codeline" id="line-219"><code>		throw("bad type passed to typePointersOfType")</code></span>
<span class="codeline" id="line-220"><code>	}</code></span>
<span class="codeline" id="line-221"><code>	if span.spanclass.noscan() {</code></span>
<span class="codeline" id="line-222"><code>		return typePointers{}</code></span>
<span class="codeline" id="line-223"><code>	}</code></span>
<span class="codeline" id="line-224"><code>	// Since we have the type, pretend we have a header.</code></span>
<span class="codeline" id="line-225"><code>	gcdata := typ.GCData</code></span>
<span class="codeline" id="line-226"><code>	return typePointers{elem: addr, addr: addr, mask: readUintptr(gcdata), typ: typ}</code></span>
<span class="codeline" id="line-227"><code>}</code></span>
<span class="codeline" id="line-228"><code></code></span>
<span class="codeline" id="line-229"><code>// nextFast is the fast path of next. nextFast is written to be inlineable and,</code></span>
<span class="codeline" id="line-230"><code>// as the name implies, fast.</code></span>
<span class="codeline" id="line-231"><code>//</code></span>
<span class="codeline" id="line-232"><code>// Callers that are performance-critical should iterate using the following</code></span>
<span class="codeline" id="line-233"><code>// pattern:</code></span>
<span class="codeline" id="line-234"><code>//</code></span>
<span class="codeline" id="line-235"><code>//	for {</code></span>
<span class="codeline" id="line-236"><code>//		var addr uintptr</code></span>
<span class="codeline" id="line-237"><code>//		if tp, addr = tp.nextFast(); addr == 0 {</code></span>
<span class="codeline" id="line-238"><code>//			if tp, addr = tp.next(limit); addr == 0 {</code></span>
<span class="codeline" id="line-239"><code>//				break</code></span>
<span class="codeline" id="line-240"><code>//			}</code></span>
<span class="codeline" id="line-241"><code>//		}</code></span>
<span class="codeline" id="line-242"><code>//		// Use addr.</code></span>
<span class="codeline" id="line-243"><code>//		...</code></span>
<span class="codeline" id="line-244"><code>//	}</code></span>
<span class="codeline" id="line-245"><code>//</code></span>
<span class="codeline" id="line-246"><code>// nosplit because it is used during write barriers and must not be preempted.</code></span>
<span class="codeline" id="line-247"><code>//</code></span>
<span class="codeline" id="line-248"><code>//go:nosplit</code></span>
<span class="codeline" id="line-249"><code>func (tp typePointers) nextFast() (typePointers, uintptr) {</code></span>
<span class="codeline" id="line-250"><code>	// TESTQ/JEQ</code></span>
<span class="codeline" id="line-251"><code>	if tp.mask == 0 {</code></span>
<span class="codeline" id="line-252"><code>		return tp, 0</code></span>
<span class="codeline" id="line-253"><code>	}</code></span>
<span class="codeline" id="line-254"><code>	// BSFQ</code></span>
<span class="codeline" id="line-255"><code>	var i int</code></span>
<span class="codeline" id="line-256"><code>	if goarch.PtrSize == 8 {</code></span>
<span class="codeline" id="line-257"><code>		i = sys.TrailingZeros64(uint64(tp.mask))</code></span>
<span class="codeline" id="line-258"><code>	} else {</code></span>
<span class="codeline" id="line-259"><code>		i = sys.TrailingZeros32(uint32(tp.mask))</code></span>
<span class="codeline" id="line-260"><code>	}</code></span>
<span class="codeline" id="line-261"><code>	// BTCQ</code></span>
<span class="codeline" id="line-262"><code>	tp.mask ^= uintptr(1) &lt;&lt; (i &amp; (ptrBits - 1))</code></span>
<span class="codeline" id="line-263"><code>	// LEAQ (XX)(XX*8)</code></span>
<span class="codeline" id="line-264"><code>	return tp, tp.addr + uintptr(i)*goarch.PtrSize</code></span>
<span class="codeline" id="line-265"><code>}</code></span>
<span class="codeline" id="line-266"><code></code></span>
<span class="codeline" id="line-267"><code>// next advances the pointers iterator, returning the updated iterator and</code></span>
<span class="codeline" id="line-268"><code>// the address of the next pointer.</code></span>
<span class="codeline" id="line-269"><code>//</code></span>
<span class="codeline" id="line-270"><code>// limit must be the same each time it is passed to next.</code></span>
<span class="codeline" id="line-271"><code>//</code></span>
<span class="codeline" id="line-272"><code>// nosplit because it is used during write barriers and must not be preempted.</code></span>
<span class="codeline" id="line-273"><code>//</code></span>
<span class="codeline" id="line-274"><code>//go:nosplit</code></span>
<span class="codeline" id="line-275"><code>func (tp typePointers) next(limit uintptr) (typePointers, uintptr) {</code></span>
<span class="codeline" id="line-276"><code>	for {</code></span>
<span class="codeline" id="line-277"><code>		if tp.mask != 0 {</code></span>
<span class="codeline" id="line-278"><code>			return tp.nextFast()</code></span>
<span class="codeline" id="line-279"><code>		}</code></span>
<span class="codeline" id="line-280"><code></code></span>
<span class="codeline" id="line-281"><code>		// Stop if we don't actually have type information.</code></span>
<span class="codeline" id="line-282"><code>		if tp.typ == nil {</code></span>
<span class="codeline" id="line-283"><code>			return typePointers{}, 0</code></span>
<span class="codeline" id="line-284"><code>		}</code></span>
<span class="codeline" id="line-285"><code></code></span>
<span class="codeline" id="line-286"><code>		// Advance to the next element if necessary.</code></span>
<span class="codeline" id="line-287"><code>		if tp.addr+goarch.PtrSize*ptrBits &gt;= tp.elem+tp.typ.PtrBytes {</code></span>
<span class="codeline" id="line-288"><code>			tp.elem += tp.typ.Size_</code></span>
<span class="codeline" id="line-289"><code>			tp.addr = tp.elem</code></span>
<span class="codeline" id="line-290"><code>		} else {</code></span>
<span class="codeline" id="line-291"><code>			tp.addr += ptrBits * goarch.PtrSize</code></span>
<span class="codeline" id="line-292"><code>		}</code></span>
<span class="codeline" id="line-293"><code></code></span>
<span class="codeline" id="line-294"><code>		// Check if we've exceeded the limit with the last update.</code></span>
<span class="codeline" id="line-295"><code>		if tp.addr &gt;= limit {</code></span>
<span class="codeline" id="line-296"><code>			return typePointers{}, 0</code></span>
<span class="codeline" id="line-297"><code>		}</code></span>
<span class="codeline" id="line-298"><code></code></span>
<span class="codeline" id="line-299"><code>		// Grab more bits and try again.</code></span>
<span class="codeline" id="line-300"><code>		tp.mask = readUintptr(addb(tp.typ.GCData, (tp.addr-tp.elem)/goarch.PtrSize/8))</code></span>
<span class="codeline" id="line-301"><code>		if tp.addr+goarch.PtrSize*ptrBits &gt; limit {</code></span>
<span class="codeline" id="line-302"><code>			bits := (tp.addr + goarch.PtrSize*ptrBits - limit) / goarch.PtrSize</code></span>
<span class="codeline" id="line-303"><code>			tp.mask &amp;^= ((1 &lt;&lt; (bits)) - 1) &lt;&lt; (ptrBits - bits)</code></span>
<span class="codeline" id="line-304"><code>		}</code></span>
<span class="codeline" id="line-305"><code>	}</code></span>
<span class="codeline" id="line-306"><code>}</code></span>
<span class="codeline" id="line-307"><code></code></span>
<span class="codeline" id="line-308"><code>// fastForward moves the iterator forward by n bytes. n must be a multiple</code></span>
<span class="codeline" id="line-309"><code>// of goarch.PtrSize. limit must be the same limit passed to next for this</code></span>
<span class="codeline" id="line-310"><code>// iterator.</code></span>
<span class="codeline" id="line-311"><code>//</code></span>
<span class="codeline" id="line-312"><code>// nosplit because it is used during write barriers and must not be preempted.</code></span>
<span class="codeline" id="line-313"><code>//</code></span>
<span class="codeline" id="line-314"><code>//go:nosplit</code></span>
<span class="codeline" id="line-315"><code>func (tp typePointers) fastForward(n, limit uintptr) typePointers {</code></span>
<span class="codeline" id="line-316"><code>	// Basic bounds check.</code></span>
<span class="codeline" id="line-317"><code>	target := tp.addr + n</code></span>
<span class="codeline" id="line-318"><code>	if target &gt;= limit {</code></span>
<span class="codeline" id="line-319"><code>		return typePointers{}</code></span>
<span class="codeline" id="line-320"><code>	}</code></span>
<span class="codeline" id="line-321"><code>	if tp.typ == nil {</code></span>
<span class="codeline" id="line-322"><code>		// Handle small objects.</code></span>
<span class="codeline" id="line-323"><code>		// Clear any bits before the target address.</code></span>
<span class="codeline" id="line-324"><code>		tp.mask &amp;^= (1 &lt;&lt; ((target - tp.addr) / goarch.PtrSize)) - 1</code></span>
<span class="codeline" id="line-325"><code>		// Clear any bits past the limit.</code></span>
<span class="codeline" id="line-326"><code>		if tp.addr+goarch.PtrSize*ptrBits &gt; limit {</code></span>
<span class="codeline" id="line-327"><code>			bits := (tp.addr + goarch.PtrSize*ptrBits - limit) / goarch.PtrSize</code></span>
<span class="codeline" id="line-328"><code>			tp.mask &amp;^= ((1 &lt;&lt; (bits)) - 1) &lt;&lt; (ptrBits - bits)</code></span>
<span class="codeline" id="line-329"><code>		}</code></span>
<span class="codeline" id="line-330"><code>		return tp</code></span>
<span class="codeline" id="line-331"><code>	}</code></span>
<span class="codeline" id="line-332"><code></code></span>
<span class="codeline" id="line-333"><code>	// Move up elem and addr.</code></span>
<span class="codeline" id="line-334"><code>	// Offsets within an element are always at a ptrBits*goarch.PtrSize boundary.</code></span>
<span class="codeline" id="line-335"><code>	if n &gt;= tp.typ.Size_ {</code></span>
<span class="codeline" id="line-336"><code>		// elem needs to be moved to the element containing</code></span>
<span class="codeline" id="line-337"><code>		// tp.addr + n.</code></span>
<span class="codeline" id="line-338"><code>		oldelem := tp.elem</code></span>
<span class="codeline" id="line-339"><code>		tp.elem += (tp.addr - tp.elem + n) / tp.typ.Size_ * tp.typ.Size_</code></span>
<span class="codeline" id="line-340"><code>		tp.addr = tp.elem + alignDown(n-(tp.elem-oldelem), ptrBits*goarch.PtrSize)</code></span>
<span class="codeline" id="line-341"><code>	} else {</code></span>
<span class="codeline" id="line-342"><code>		tp.addr += alignDown(n, ptrBits*goarch.PtrSize)</code></span>
<span class="codeline" id="line-343"><code>	}</code></span>
<span class="codeline" id="line-344"><code></code></span>
<span class="codeline" id="line-345"><code>	if tp.addr-tp.elem &gt;= tp.typ.PtrBytes {</code></span>
<span class="codeline" id="line-346"><code>		// We're starting in the non-pointer area of an array.</code></span>
<span class="codeline" id="line-347"><code>		// Move up to the next element.</code></span>
<span class="codeline" id="line-348"><code>		tp.elem += tp.typ.Size_</code></span>
<span class="codeline" id="line-349"><code>		tp.addr = tp.elem</code></span>
<span class="codeline" id="line-350"><code>		tp.mask = readUintptr(tp.typ.GCData)</code></span>
<span class="codeline" id="line-351"><code></code></span>
<span class="codeline" id="line-352"><code>		// We may have exceeded the limit after this. Bail just like next does.</code></span>
<span class="codeline" id="line-353"><code>		if tp.addr &gt;= limit {</code></span>
<span class="codeline" id="line-354"><code>			return typePointers{}</code></span>
<span class="codeline" id="line-355"><code>		}</code></span>
<span class="codeline" id="line-356"><code>	} else {</code></span>
<span class="codeline" id="line-357"><code>		// Grab the mask, but then clear any bits before the target address and any</code></span>
<span class="codeline" id="line-358"><code>		// bits over the limit.</code></span>
<span class="codeline" id="line-359"><code>		tp.mask = readUintptr(addb(tp.typ.GCData, (tp.addr-tp.elem)/goarch.PtrSize/8))</code></span>
<span class="codeline" id="line-360"><code>		tp.mask &amp;^= (1 &lt;&lt; ((target - tp.addr) / goarch.PtrSize)) - 1</code></span>
<span class="codeline" id="line-361"><code>	}</code></span>
<span class="codeline" id="line-362"><code>	if tp.addr+goarch.PtrSize*ptrBits &gt; limit {</code></span>
<span class="codeline" id="line-363"><code>		bits := (tp.addr + goarch.PtrSize*ptrBits - limit) / goarch.PtrSize</code></span>
<span class="codeline" id="line-364"><code>		tp.mask &amp;^= ((1 &lt;&lt; (bits)) - 1) &lt;&lt; (ptrBits - bits)</code></span>
<span class="codeline" id="line-365"><code>	}</code></span>
<span class="codeline" id="line-366"><code>	return tp</code></span>
<span class="codeline" id="line-367"><code>}</code></span>
<span class="codeline" id="line-368"><code></code></span>
<span class="codeline" id="line-369"><code>// objBase returns the base pointer for the object containing addr in span.</code></span>
<span class="codeline" id="line-370"><code>//</code></span>
<span class="codeline" id="line-371"><code>// Assumes that addr points into a valid part of span (span.base() &lt;= addr &lt; span.limit).</code></span>
<span class="codeline" id="line-372"><code>//</code></span>
<span class="codeline" id="line-373"><code>//go:nosplit</code></span>
<span class="codeline" id="line-374"><code>func (span *mspan) objBase(addr uintptr) uintptr {</code></span>
<span class="codeline" id="line-375"><code>	return span.base() + span.objIndex(addr)*span.elemsize</code></span>
<span class="codeline" id="line-376"><code>}</code></span>
<span class="codeline" id="line-377"><code></code></span>
<span class="codeline" id="line-378"><code>// bulkBarrierPreWrite executes a write barrier</code></span>
<span class="codeline" id="line-379"><code>// for every pointer slot in the memory range [src, src+size),</code></span>
<span class="codeline" id="line-380"><code>// using pointer/scalar information from [dst, dst+size).</code></span>
<span class="codeline" id="line-381"><code>// This executes the write barriers necessary before a memmove.</code></span>
<span class="codeline" id="line-382"><code>// src, dst, and size must be pointer-aligned.</code></span>
<span class="codeline" id="line-383"><code>// The range [dst, dst+size) must lie within a single object.</code></span>
<span class="codeline" id="line-384"><code>// It does not perform the actual writes.</code></span>
<span class="codeline" id="line-385"><code>//</code></span>
<span class="codeline" id="line-386"><code>// As a special case, src == 0 indicates that this is being used for a</code></span>
<span class="codeline" id="line-387"><code>// memclr. bulkBarrierPreWrite will pass 0 for the src of each write</code></span>
<span class="codeline" id="line-388"><code>// barrier.</code></span>
<span class="codeline" id="line-389"><code>//</code></span>
<span class="codeline" id="line-390"><code>// Callers should call bulkBarrierPreWrite immediately before</code></span>
<span class="codeline" id="line-391"><code>// calling memmove(dst, src, size). This function is marked nosplit</code></span>
<span class="codeline" id="line-392"><code>// to avoid being preempted; the GC must not stop the goroutine</code></span>
<span class="codeline" id="line-393"><code>// between the memmove and the execution of the barriers.</code></span>
<span class="codeline" id="line-394"><code>// The caller is also responsible for cgo pointer checks if this</code></span>
<span class="codeline" id="line-395"><code>// may be writing Go pointers into non-Go memory.</code></span>
<span class="codeline" id="line-396"><code>//</code></span>
<span class="codeline" id="line-397"><code>// Pointer data is not maintained for allocations containing</code></span>
<span class="codeline" id="line-398"><code>// no pointers at all; any caller of bulkBarrierPreWrite must first</code></span>
<span class="codeline" id="line-399"><code>// make sure the underlying allocation contains pointers, usually</code></span>
<span class="codeline" id="line-400"><code>// by checking typ.PtrBytes.</code></span>
<span class="codeline" id="line-401"><code>//</code></span>
<span class="codeline" id="line-402"><code>// The typ argument is the type of the space at src and dst (and the</code></span>
<span class="codeline" id="line-403"><code>// element type if src and dst refer to arrays) and it is optional.</code></span>
<span class="codeline" id="line-404"><code>// If typ is nil, the barrier will still behave as expected and typ</code></span>
<span class="codeline" id="line-405"><code>// is used purely as an optimization. However, it must be used with</code></span>
<span class="codeline" id="line-406"><code>// care.</code></span>
<span class="codeline" id="line-407"><code>//</code></span>
<span class="codeline" id="line-408"><code>// If typ is not nil, then src and dst must point to one or more values</code></span>
<span class="codeline" id="line-409"><code>// of type typ. The caller must ensure that the ranges [src, src+size)</code></span>
<span class="codeline" id="line-410"><code>// and [dst, dst+size) refer to one or more whole values of type src and</code></span>
<span class="codeline" id="line-411"><code>// dst (leaving off the pointerless tail of the space is OK). If this</code></span>
<span class="codeline" id="line-412"><code>// precondition is not followed, this function will fail to scan the</code></span>
<span class="codeline" id="line-413"><code>// right pointers.</code></span>
<span class="codeline" id="line-414"><code>//</code></span>
<span class="codeline" id="line-415"><code>// When in doubt, pass nil for typ. That is safe and will always work.</code></span>
<span class="codeline" id="line-416"><code>//</code></span>
<span class="codeline" id="line-417"><code>// Callers must perform cgo checks if goexperiment.CgoCheck2.</code></span>
<span class="codeline" id="line-418"><code>//</code></span>
<span class="codeline" id="line-419"><code>//go:nosplit</code></span>
<span class="codeline" id="line-420"><code>func bulkBarrierPreWrite(dst, src, size uintptr, typ *abi.Type) {</code></span>
<span class="codeline" id="line-421"><code>	if (dst|src|size)&amp;(goarch.PtrSize-1) != 0 {</code></span>
<span class="codeline" id="line-422"><code>		throw("bulkBarrierPreWrite: unaligned arguments")</code></span>
<span class="codeline" id="line-423"><code>	}</code></span>
<span class="codeline" id="line-424"><code>	if !writeBarrier.enabled {</code></span>
<span class="codeline" id="line-425"><code>		return</code></span>
<span class="codeline" id="line-426"><code>	}</code></span>
<span class="codeline" id="line-427"><code>	s := spanOf(dst)</code></span>
<span class="codeline" id="line-428"><code>	if s == nil {</code></span>
<span class="codeline" id="line-429"><code>		// If dst is a global, use the data or BSS bitmaps to</code></span>
<span class="codeline" id="line-430"><code>		// execute write barriers.</code></span>
<span class="codeline" id="line-431"><code>		for _, datap := range activeModules() {</code></span>
<span class="codeline" id="line-432"><code>			if datap.data &lt;= dst &amp;&amp; dst &lt; datap.edata {</code></span>
<span class="codeline" id="line-433"><code>				bulkBarrierBitmap(dst, src, size, dst-datap.data, datap.gcdatamask.bytedata)</code></span>
<span class="codeline" id="line-434"><code>				return</code></span>
<span class="codeline" id="line-435"><code>			}</code></span>
<span class="codeline" id="line-436"><code>		}</code></span>
<span class="codeline" id="line-437"><code>		for _, datap := range activeModules() {</code></span>
<span class="codeline" id="line-438"><code>			if datap.bss &lt;= dst &amp;&amp; dst &lt; datap.ebss {</code></span>
<span class="codeline" id="line-439"><code>				bulkBarrierBitmap(dst, src, size, dst-datap.bss, datap.gcbssmask.bytedata)</code></span>
<span class="codeline" id="line-440"><code>				return</code></span>
<span class="codeline" id="line-441"><code>			}</code></span>
<span class="codeline" id="line-442"><code>		}</code></span>
<span class="codeline" id="line-443"><code>		return</code></span>
<span class="codeline" id="line-444"><code>	} else if s.state.get() != mSpanInUse || dst &lt; s.base() || s.limit &lt;= dst {</code></span>
<span class="codeline" id="line-445"><code>		// dst was heap memory at some point, but isn't now.</code></span>
<span class="codeline" id="line-446"><code>		// It can't be a global. It must be either our stack,</code></span>
<span class="codeline" id="line-447"><code>		// or in the case of direct channel sends, it could be</code></span>
<span class="codeline" id="line-448"><code>		// another stack. Either way, no need for barriers.</code></span>
<span class="codeline" id="line-449"><code>		// This will also catch if dst is in a freed span,</code></span>
<span class="codeline" id="line-450"><code>		// though that should never have.</code></span>
<span class="codeline" id="line-451"><code>		return</code></span>
<span class="codeline" id="line-452"><code>	}</code></span>
<span class="codeline" id="line-453"><code>	buf := &amp;getg().m.p.ptr().wbBuf</code></span>
<span class="codeline" id="line-454"><code></code></span>
<span class="codeline" id="line-455"><code>	// Double-check that the bitmaps generated in the two possible paths match.</code></span>
<span class="codeline" id="line-456"><code>	const doubleCheck = false</code></span>
<span class="codeline" id="line-457"><code>	if doubleCheck {</code></span>
<span class="codeline" id="line-458"><code>		doubleCheckTypePointersOfType(s, typ, dst, size)</code></span>
<span class="codeline" id="line-459"><code>	}</code></span>
<span class="codeline" id="line-460"><code></code></span>
<span class="codeline" id="line-461"><code>	var tp typePointers</code></span>
<span class="codeline" id="line-462"><code>	if typ != nil &amp;&amp; typ.Kind_&amp;kindGCProg == 0 {</code></span>
<span class="codeline" id="line-463"><code>		tp = s.typePointersOfType(typ, dst)</code></span>
<span class="codeline" id="line-464"><code>	} else {</code></span>
<span class="codeline" id="line-465"><code>		tp = s.typePointersOf(dst, size)</code></span>
<span class="codeline" id="line-466"><code>	}</code></span>
<span class="codeline" id="line-467"><code>	if src == 0 {</code></span>
<span class="codeline" id="line-468"><code>		for {</code></span>
<span class="codeline" id="line-469"><code>			var addr uintptr</code></span>
<span class="codeline" id="line-470"><code>			if tp, addr = tp.next(dst + size); addr == 0 {</code></span>
<span class="codeline" id="line-471"><code>				break</code></span>
<span class="codeline" id="line-472"><code>			}</code></span>
<span class="codeline" id="line-473"><code>			dstx := (*uintptr)(unsafe.Pointer(addr))</code></span>
<span class="codeline" id="line-474"><code>			p := buf.get1()</code></span>
<span class="codeline" id="line-475"><code>			p[0] = *dstx</code></span>
<span class="codeline" id="line-476"><code>		}</code></span>
<span class="codeline" id="line-477"><code>	} else {</code></span>
<span class="codeline" id="line-478"><code>		for {</code></span>
<span class="codeline" id="line-479"><code>			var addr uintptr</code></span>
<span class="codeline" id="line-480"><code>			if tp, addr = tp.next(dst + size); addr == 0 {</code></span>
<span class="codeline" id="line-481"><code>				break</code></span>
<span class="codeline" id="line-482"><code>			}</code></span>
<span class="codeline" id="line-483"><code>			dstx := (*uintptr)(unsafe.Pointer(addr))</code></span>
<span class="codeline" id="line-484"><code>			srcx := (*uintptr)(unsafe.Pointer(src + (addr - dst)))</code></span>
<span class="codeline" id="line-485"><code>			p := buf.get2()</code></span>
<span class="codeline" id="line-486"><code>			p[0] = *dstx</code></span>
<span class="codeline" id="line-487"><code>			p[1] = *srcx</code></span>
<span class="codeline" id="line-488"><code>		}</code></span>
<span class="codeline" id="line-489"><code>	}</code></span>
<span class="codeline" id="line-490"><code>}</code></span>
<span class="codeline" id="line-491"><code></code></span>
<span class="codeline" id="line-492"><code>// bulkBarrierPreWriteSrcOnly is like bulkBarrierPreWrite but</code></span>
<span class="codeline" id="line-493"><code>// does not execute write barriers for [dst, dst+size).</code></span>
<span class="codeline" id="line-494"><code>//</code></span>
<span class="codeline" id="line-495"><code>// In addition to the requirements of bulkBarrierPreWrite</code></span>
<span class="codeline" id="line-496"><code>// callers need to ensure [dst, dst+size) is zeroed.</code></span>
<span class="codeline" id="line-497"><code>//</code></span>
<span class="codeline" id="line-498"><code>// This is used for special cases where e.g. dst was just</code></span>
<span class="codeline" id="line-499"><code>// created and zeroed with malloc.</code></span>
<span class="codeline" id="line-500"><code>//</code></span>
<span class="codeline" id="line-501"><code>// The type of the space can be provided purely as an optimization.</code></span>
<span class="codeline" id="line-502"><code>// See bulkBarrierPreWrite's comment for more details -- use this</code></span>
<span class="codeline" id="line-503"><code>// optimization with great care.</code></span>
<span class="codeline" id="line-504"><code>//</code></span>
<span class="codeline" id="line-505"><code>//go:nosplit</code></span>
<span class="codeline" id="line-506"><code>func bulkBarrierPreWriteSrcOnly(dst, src, size uintptr, typ *abi.Type) {</code></span>
<span class="codeline" id="line-507"><code>	if (dst|src|size)&amp;(goarch.PtrSize-1) != 0 {</code></span>
<span class="codeline" id="line-508"><code>		throw("bulkBarrierPreWrite: unaligned arguments")</code></span>
<span class="codeline" id="line-509"><code>	}</code></span>
<span class="codeline" id="line-510"><code>	if !writeBarrier.enabled {</code></span>
<span class="codeline" id="line-511"><code>		return</code></span>
<span class="codeline" id="line-512"><code>	}</code></span>
<span class="codeline" id="line-513"><code>	buf := &amp;getg().m.p.ptr().wbBuf</code></span>
<span class="codeline" id="line-514"><code>	s := spanOf(dst)</code></span>
<span class="codeline" id="line-515"><code></code></span>
<span class="codeline" id="line-516"><code>	// Double-check that the bitmaps generated in the two possible paths match.</code></span>
<span class="codeline" id="line-517"><code>	const doubleCheck = false</code></span>
<span class="codeline" id="line-518"><code>	if doubleCheck {</code></span>
<span class="codeline" id="line-519"><code>		doubleCheckTypePointersOfType(s, typ, dst, size)</code></span>
<span class="codeline" id="line-520"><code>	}</code></span>
<span class="codeline" id="line-521"><code></code></span>
<span class="codeline" id="line-522"><code>	var tp typePointers</code></span>
<span class="codeline" id="line-523"><code>	if typ != nil &amp;&amp; typ.Kind_&amp;kindGCProg == 0 {</code></span>
<span class="codeline" id="line-524"><code>		tp = s.typePointersOfType(typ, dst)</code></span>
<span class="codeline" id="line-525"><code>	} else {</code></span>
<span class="codeline" id="line-526"><code>		tp = s.typePointersOf(dst, size)</code></span>
<span class="codeline" id="line-527"><code>	}</code></span>
<span class="codeline" id="line-528"><code>	for {</code></span>
<span class="codeline" id="line-529"><code>		var addr uintptr</code></span>
<span class="codeline" id="line-530"><code>		if tp, addr = tp.next(dst + size); addr == 0 {</code></span>
<span class="codeline" id="line-531"><code>			break</code></span>
<span class="codeline" id="line-532"><code>		}</code></span>
<span class="codeline" id="line-533"><code>		srcx := (*uintptr)(unsafe.Pointer(addr - dst + src))</code></span>
<span class="codeline" id="line-534"><code>		p := buf.get1()</code></span>
<span class="codeline" id="line-535"><code>		p[0] = *srcx</code></span>
<span class="codeline" id="line-536"><code>	}</code></span>
<span class="codeline" id="line-537"><code>}</code></span>
<span class="codeline" id="line-538"><code></code></span>
<span class="codeline" id="line-539"><code>// initHeapBits initializes the heap bitmap for a span.</code></span>
<span class="codeline" id="line-540"><code>//</code></span>
<span class="codeline" id="line-541"><code>// TODO(mknyszek): This should set the heap bits for single pointer</code></span>
<span class="codeline" id="line-542"><code>// allocations eagerly to avoid calling heapSetType at allocation time,</code></span>
<span class="codeline" id="line-543"><code>// just to write one bit.</code></span>
<span class="codeline" id="line-544"><code>func (s *mspan) initHeapBits(forceClear bool) {</code></span>
<span class="codeline" id="line-545"><code>	if (!s.spanclass.noscan() &amp;&amp; heapBitsInSpan(s.elemsize)) || s.isUserArenaChunk {</code></span>
<span class="codeline" id="line-546"><code>		b := s.heapBits()</code></span>
<span class="codeline" id="line-547"><code>		for i := range b {</code></span>
<span class="codeline" id="line-548"><code>			b[i] = 0</code></span>
<span class="codeline" id="line-549"><code>		}</code></span>
<span class="codeline" id="line-550"><code>	}</code></span>
<span class="codeline" id="line-551"><code>}</code></span>
<span class="codeline" id="line-552"><code></code></span>
<span class="codeline" id="line-553"><code>// bswapIfBigEndian swaps the byte order of the uintptr on goarch.BigEndian platforms,</code></span>
<span class="codeline" id="line-554"><code>// and leaves it alone elsewhere.</code></span>
<span class="codeline" id="line-555"><code>func bswapIfBigEndian(x uintptr) uintptr {</code></span>
<span class="codeline" id="line-556"><code>	if goarch.BigEndian {</code></span>
<span class="codeline" id="line-557"><code>		if goarch.PtrSize == 8 {</code></span>
<span class="codeline" id="line-558"><code>			return uintptr(sys.Bswap64(uint64(x)))</code></span>
<span class="codeline" id="line-559"><code>		}</code></span>
<span class="codeline" id="line-560"><code>		return uintptr(sys.Bswap32(uint32(x)))</code></span>
<span class="codeline" id="line-561"><code>	}</code></span>
<span class="codeline" id="line-562"><code>	return x</code></span>
<span class="codeline" id="line-563"><code>}</code></span>
<span class="codeline" id="line-564"><code></code></span>
<span class="codeline" id="line-565"><code>type writeUserArenaHeapBits struct {</code></span>
<span class="codeline" id="line-566"><code>	offset uintptr // offset in span that the low bit of mask represents the pointer state of.</code></span>
<span class="codeline" id="line-567"><code>	mask   uintptr // some pointer bits starting at the address addr.</code></span>
<span class="codeline" id="line-568"><code>	valid  uintptr // number of bits in buf that are valid (including low)</code></span>
<span class="codeline" id="line-569"><code>	low    uintptr // number of low-order bits to not overwrite</code></span>
<span class="codeline" id="line-570"><code>}</code></span>
<span class="codeline" id="line-571"><code></code></span>
<span class="codeline" id="line-572"><code>func (s *mspan) writeUserArenaHeapBits(addr uintptr) (h writeUserArenaHeapBits) {</code></span>
<span class="codeline" id="line-573"><code>	offset := addr - s.base()</code></span>
<span class="codeline" id="line-574"><code></code></span>
<span class="codeline" id="line-575"><code>	// We start writing bits maybe in the middle of a heap bitmap word.</code></span>
<span class="codeline" id="line-576"><code>	// Remember how many bits into the word we started, so we can be sure</code></span>
<span class="codeline" id="line-577"><code>	// not to overwrite the previous bits.</code></span>
<span class="codeline" id="line-578"><code>	h.low = offset / goarch.PtrSize % ptrBits</code></span>
<span class="codeline" id="line-579"><code></code></span>
<span class="codeline" id="line-580"><code>	// round down to heap word that starts the bitmap word.</code></span>
<span class="codeline" id="line-581"><code>	h.offset = offset - h.low*goarch.PtrSize</code></span>
<span class="codeline" id="line-582"><code></code></span>
<span class="codeline" id="line-583"><code>	// We don't have any bits yet.</code></span>
<span class="codeline" id="line-584"><code>	h.mask = 0</code></span>
<span class="codeline" id="line-585"><code>	h.valid = h.low</code></span>
<span class="codeline" id="line-586"><code></code></span>
<span class="codeline" id="line-587"><code>	return</code></span>
<span class="codeline" id="line-588"><code>}</code></span>
<span class="codeline" id="line-589"><code></code></span>
<span class="codeline" id="line-590"><code>// write appends the pointerness of the next valid pointer slots</code></span>
<span class="codeline" id="line-591"><code>// using the low valid bits of bits. 1=pointer, 0=scalar.</code></span>
<span class="codeline" id="line-592"><code>func (h writeUserArenaHeapBits) write(s *mspan, bits, valid uintptr) writeUserArenaHeapBits {</code></span>
<span class="codeline" id="line-593"><code>	if h.valid+valid &lt;= ptrBits {</code></span>
<span class="codeline" id="line-594"><code>		// Fast path - just accumulate the bits.</code></span>
<span class="codeline" id="line-595"><code>		h.mask |= bits &lt;&lt; h.valid</code></span>
<span class="codeline" id="line-596"><code>		h.valid += valid</code></span>
<span class="codeline" id="line-597"><code>		return h</code></span>
<span class="codeline" id="line-598"><code>	}</code></span>
<span class="codeline" id="line-599"><code>	// Too many bits to fit in this word. Write the current word</code></span>
<span class="codeline" id="line-600"><code>	// out and move on to the next word.</code></span>
<span class="codeline" id="line-601"><code></code></span>
<span class="codeline" id="line-602"><code>	data := h.mask | bits&lt;&lt;h.valid       // mask for this word</code></span>
<span class="codeline" id="line-603"><code>	h.mask = bits &gt;&gt; (ptrBits - h.valid) // leftover for next word</code></span>
<span class="codeline" id="line-604"><code>	h.valid += valid - ptrBits           // have h.valid+valid bits, writing ptrBits of them</code></span>
<span class="codeline" id="line-605"><code></code></span>
<span class="codeline" id="line-606"><code>	// Flush mask to the memory bitmap.</code></span>
<span class="codeline" id="line-607"><code>	idx := h.offset / (ptrBits * goarch.PtrSize)</code></span>
<span class="codeline" id="line-608"><code>	m := uintptr(1)&lt;&lt;h.low - 1</code></span>
<span class="codeline" id="line-609"><code>	bitmap := s.heapBits()</code></span>
<span class="codeline" id="line-610"><code>	bitmap[idx] = bswapIfBigEndian(bswapIfBigEndian(bitmap[idx])&amp;m | data)</code></span>
<span class="codeline" id="line-611"><code>	// Note: no synchronization required for this write because</code></span>
<span class="codeline" id="line-612"><code>	// the allocator has exclusive access to the page, and the bitmap</code></span>
<span class="codeline" id="line-613"><code>	// entries are all for a single page. Also, visibility of these</code></span>
<span class="codeline" id="line-614"><code>	// writes is guaranteed by the publication barrier in mallocgc.</code></span>
<span class="codeline" id="line-615"><code></code></span>
<span class="codeline" id="line-616"><code>	// Move to next word of bitmap.</code></span>
<span class="codeline" id="line-617"><code>	h.offset += ptrBits * goarch.PtrSize</code></span>
<span class="codeline" id="line-618"><code>	h.low = 0</code></span>
<span class="codeline" id="line-619"><code>	return h</code></span>
<span class="codeline" id="line-620"><code>}</code></span>
<span class="codeline" id="line-621"><code></code></span>
<span class="codeline" id="line-622"><code>// Add padding of size bytes.</code></span>
<span class="codeline" id="line-623"><code>func (h writeUserArenaHeapBits) pad(s *mspan, size uintptr) writeUserArenaHeapBits {</code></span>
<span class="codeline" id="line-624"><code>	if size == 0 {</code></span>
<span class="codeline" id="line-625"><code>		return h</code></span>
<span class="codeline" id="line-626"><code>	}</code></span>
<span class="codeline" id="line-627"><code>	words := size / goarch.PtrSize</code></span>
<span class="codeline" id="line-628"><code>	for words &gt; ptrBits {</code></span>
<span class="codeline" id="line-629"><code>		h = h.write(s, 0, ptrBits)</code></span>
<span class="codeline" id="line-630"><code>		words -= ptrBits</code></span>
<span class="codeline" id="line-631"><code>	}</code></span>
<span class="codeline" id="line-632"><code>	return h.write(s, 0, words)</code></span>
<span class="codeline" id="line-633"><code>}</code></span>
<span class="codeline" id="line-634"><code></code></span>
<span class="codeline" id="line-635"><code>// Flush the bits that have been written, and add zeros as needed</code></span>
<span class="codeline" id="line-636"><code>// to cover the full object [addr, addr+size).</code></span>
<span class="codeline" id="line-637"><code>func (h writeUserArenaHeapBits) flush(s *mspan, addr, size uintptr) {</code></span>
<span class="codeline" id="line-638"><code>	offset := addr - s.base()</code></span>
<span class="codeline" id="line-639"><code></code></span>
<span class="codeline" id="line-640"><code>	// zeros counts the number of bits needed to represent the object minus the</code></span>
<span class="codeline" id="line-641"><code>	// number of bits we've already written. This is the number of 0 bits</code></span>
<span class="codeline" id="line-642"><code>	// that need to be added.</code></span>
<span class="codeline" id="line-643"><code>	zeros := (offset+size-h.offset)/goarch.PtrSize - h.valid</code></span>
<span class="codeline" id="line-644"><code></code></span>
<span class="codeline" id="line-645"><code>	// Add zero bits up to the bitmap word boundary</code></span>
<span class="codeline" id="line-646"><code>	if zeros &gt; 0 {</code></span>
<span class="codeline" id="line-647"><code>		z := ptrBits - h.valid</code></span>
<span class="codeline" id="line-648"><code>		if z &gt; zeros {</code></span>
<span class="codeline" id="line-649"><code>			z = zeros</code></span>
<span class="codeline" id="line-650"><code>		}</code></span>
<span class="codeline" id="line-651"><code>		h.valid += z</code></span>
<span class="codeline" id="line-652"><code>		zeros -= z</code></span>
<span class="codeline" id="line-653"><code>	}</code></span>
<span class="codeline" id="line-654"><code></code></span>
<span class="codeline" id="line-655"><code>	// Find word in bitmap that we're going to write.</code></span>
<span class="codeline" id="line-656"><code>	bitmap := s.heapBits()</code></span>
<span class="codeline" id="line-657"><code>	idx := h.offset / (ptrBits * goarch.PtrSize)</code></span>
<span class="codeline" id="line-658"><code></code></span>
<span class="codeline" id="line-659"><code>	// Write remaining bits.</code></span>
<span class="codeline" id="line-660"><code>	if h.valid != h.low {</code></span>
<span class="codeline" id="line-661"><code>		m := uintptr(1)&lt;&lt;h.low - 1      // don't clear existing bits below "low"</code></span>
<span class="codeline" id="line-662"><code>		m |= ^(uintptr(1)&lt;&lt;h.valid - 1) // don't clear existing bits above "valid"</code></span>
<span class="codeline" id="line-663"><code>		bitmap[idx] = bswapIfBigEndian(bswapIfBigEndian(bitmap[idx])&amp;m | h.mask)</code></span>
<span class="codeline" id="line-664"><code>	}</code></span>
<span class="codeline" id="line-665"><code>	if zeros == 0 {</code></span>
<span class="codeline" id="line-666"><code>		return</code></span>
<span class="codeline" id="line-667"><code>	}</code></span>
<span class="codeline" id="line-668"><code></code></span>
<span class="codeline" id="line-669"><code>	// Advance to next bitmap word.</code></span>
<span class="codeline" id="line-670"><code>	h.offset += ptrBits * goarch.PtrSize</code></span>
<span class="codeline" id="line-671"><code></code></span>
<span class="codeline" id="line-672"><code>	// Continue on writing zeros for the rest of the object.</code></span>
<span class="codeline" id="line-673"><code>	// For standard use of the ptr bits this is not required, as</code></span>
<span class="codeline" id="line-674"><code>	// the bits are read from the beginning of the object. Some uses,</code></span>
<span class="codeline" id="line-675"><code>	// like noscan spans, oblets, bulk write barriers, and cgocheck, might</code></span>
<span class="codeline" id="line-676"><code>	// start mid-object, so these writes are still required.</code></span>
<span class="codeline" id="line-677"><code>	for {</code></span>
<span class="codeline" id="line-678"><code>		// Write zero bits.</code></span>
<span class="codeline" id="line-679"><code>		idx := h.offset / (ptrBits * goarch.PtrSize)</code></span>
<span class="codeline" id="line-680"><code>		if zeros &lt; ptrBits {</code></span>
<span class="codeline" id="line-681"><code>			bitmap[idx] = bswapIfBigEndian(bswapIfBigEndian(bitmap[idx]) &amp;^ (uintptr(1)&lt;&lt;zeros - 1))</code></span>
<span class="codeline" id="line-682"><code>			break</code></span>
<span class="codeline" id="line-683"><code>		} else if zeros == ptrBits {</code></span>
<span class="codeline" id="line-684"><code>			bitmap[idx] = 0</code></span>
<span class="codeline" id="line-685"><code>			break</code></span>
<span class="codeline" id="line-686"><code>		} else {</code></span>
<span class="codeline" id="line-687"><code>			bitmap[idx] = 0</code></span>
<span class="codeline" id="line-688"><code>			zeros -= ptrBits</code></span>
<span class="codeline" id="line-689"><code>		}</code></span>
<span class="codeline" id="line-690"><code>		h.offset += ptrBits * goarch.PtrSize</code></span>
<span class="codeline" id="line-691"><code>	}</code></span>
<span class="codeline" id="line-692"><code>}</code></span>
<span class="codeline" id="line-693"><code></code></span>
<span class="codeline" id="line-694"><code>// heapBits returns the heap ptr/scalar bits stored at the end of the span for</code></span>
<span class="codeline" id="line-695"><code>// small object spans and heap arena spans.</code></span>
<span class="codeline" id="line-696"><code>//</code></span>
<span class="codeline" id="line-697"><code>// Note that the uintptr of each element means something different for small object</code></span>
<span class="codeline" id="line-698"><code>// spans and for heap arena spans. Small object spans are easy: they're never interpreted</code></span>
<span class="codeline" id="line-699"><code>// as anything but uintptr, so they're immune to differences in endianness. However, the</code></span>
<span class="codeline" id="line-700"><code>// heapBits for user arena spans is exposed through a dummy type descriptor, so the byte</code></span>
<span class="codeline" id="line-701"><code>// ordering needs to match the same byte ordering the compiler would emit. The compiler always</code></span>
<span class="codeline" id="line-702"><code>// emits the bitmap data in little endian byte ordering, so on big endian platforms these</code></span>
<span class="codeline" id="line-703"><code>// uintptrs will have their byte orders swapped from what they normally would be.</code></span>
<span class="codeline" id="line-704"><code>//</code></span>
<span class="codeline" id="line-705"><code>// heapBitsInSpan(span.elemsize) or span.isUserArenaChunk must be true.</code></span>
<span class="codeline" id="line-706"><code>//</code></span>
<span class="codeline" id="line-707"><code>//go:nosplit</code></span>
<span class="codeline" id="line-708"><code>func (span *mspan) heapBits() []uintptr {</code></span>
<span class="codeline" id="line-709"><code>	const doubleCheck = false</code></span>
<span class="codeline" id="line-710"><code></code></span>
<span class="codeline" id="line-711"><code>	if doubleCheck &amp;&amp; !span.isUserArenaChunk {</code></span>
<span class="codeline" id="line-712"><code>		if span.spanclass.noscan() {</code></span>
<span class="codeline" id="line-713"><code>			throw("heapBits called for noscan")</code></span>
<span class="codeline" id="line-714"><code>		}</code></span>
<span class="codeline" id="line-715"><code>		if span.elemsize &gt; minSizeForMallocHeader {</code></span>
<span class="codeline" id="line-716"><code>			throw("heapBits called for span class that should have a malloc header")</code></span>
<span class="codeline" id="line-717"><code>		}</code></span>
<span class="codeline" id="line-718"><code>	}</code></span>
<span class="codeline" id="line-719"><code>	// Find the bitmap at the end of the span.</code></span>
<span class="codeline" id="line-720"><code>	//</code></span>
<span class="codeline" id="line-721"><code>	// Nearly every span with heap bits is exactly one page in size. Arenas are the only exception.</code></span>
<span class="codeline" id="line-722"><code>	if span.npages == 1 {</code></span>
<span class="codeline" id="line-723"><code>		// This will be inlined and constant-folded down.</code></span>
<span class="codeline" id="line-724"><code>		return heapBitsSlice(span.base(), pageSize)</code></span>
<span class="codeline" id="line-725"><code>	}</code></span>
<span class="codeline" id="line-726"><code>	return heapBitsSlice(span.base(), span.npages*pageSize)</code></span>
<span class="codeline" id="line-727"><code>}</code></span>
<span class="codeline" id="line-728"><code></code></span>
<span class="codeline" id="line-729"><code>// Helper for constructing a slice for the span's heap bits.</code></span>
<span class="codeline" id="line-730"><code>//</code></span>
<span class="codeline" id="line-731"><code>//go:nosplit</code></span>
<span class="codeline" id="line-732"><code>func heapBitsSlice(spanBase, spanSize uintptr) []uintptr {</code></span>
<span class="codeline" id="line-733"><code>	bitmapSize := spanSize / goarch.PtrSize / 8</code></span>
<span class="codeline" id="line-734"><code>	elems := int(bitmapSize / goarch.PtrSize)</code></span>
<span class="codeline" id="line-735"><code>	var sl notInHeapSlice</code></span>
<span class="codeline" id="line-736"><code>	sl = notInHeapSlice{(*notInHeap)(unsafe.Pointer(spanBase + spanSize - bitmapSize)), elems, elems}</code></span>
<span class="codeline" id="line-737"><code>	return *(*[]uintptr)(unsafe.Pointer(&amp;sl))</code></span>
<span class="codeline" id="line-738"><code>}</code></span>
<span class="codeline" id="line-739"><code></code></span>
<span class="codeline" id="line-740"><code>// heapBitsSmallForAddr loads the heap bits for the object stored at addr from span.heapBits.</code></span>
<span class="codeline" id="line-741"><code>//</code></span>
<span class="codeline" id="line-742"><code>// addr must be the base pointer of an object in the span. heapBitsInSpan(span.elemsize)</code></span>
<span class="codeline" id="line-743"><code>// must be true.</code></span>
<span class="codeline" id="line-744"><code>//</code></span>
<span class="codeline" id="line-745"><code>//go:nosplit</code></span>
<span class="codeline" id="line-746"><code>func (span *mspan) heapBitsSmallForAddr(addr uintptr) uintptr {</code></span>
<span class="codeline" id="line-747"><code>	spanSize := span.npages * pageSize</code></span>
<span class="codeline" id="line-748"><code>	bitmapSize := spanSize / goarch.PtrSize / 8</code></span>
<span class="codeline" id="line-749"><code>	hbits := (*byte)(unsafe.Pointer(span.base() + spanSize - bitmapSize))</code></span>
<span class="codeline" id="line-750"><code></code></span>
<span class="codeline" id="line-751"><code>	// These objects are always small enough that their bitmaps</code></span>
<span class="codeline" id="line-752"><code>	// fit in a single word, so just load the word or two we need.</code></span>
<span class="codeline" id="line-753"><code>	//</code></span>
<span class="codeline" id="line-754"><code>	// Mirrors mspan.writeHeapBitsSmall.</code></span>
<span class="codeline" id="line-755"><code>	//</code></span>
<span class="codeline" id="line-756"><code>	// We should be using heapBits(), but unfortunately it introduces</code></span>
<span class="codeline" id="line-757"><code>	// both bounds checks panics and throw which causes us to exceed</code></span>
<span class="codeline" id="line-758"><code>	// the nosplit limit in quite a few cases.</code></span>
<span class="codeline" id="line-759"><code>	i := (addr - span.base()) / goarch.PtrSize / ptrBits</code></span>
<span class="codeline" id="line-760"><code>	j := (addr - span.base()) / goarch.PtrSize % ptrBits</code></span>
<span class="codeline" id="line-761"><code>	bits := span.elemsize / goarch.PtrSize</code></span>
<span class="codeline" id="line-762"><code>	word0 := (*uintptr)(unsafe.Pointer(addb(hbits, goarch.PtrSize*(i+0))))</code></span>
<span class="codeline" id="line-763"><code>	word1 := (*uintptr)(unsafe.Pointer(addb(hbits, goarch.PtrSize*(i+1))))</code></span>
<span class="codeline" id="line-764"><code></code></span>
<span class="codeline" id="line-765"><code>	var read uintptr</code></span>
<span class="codeline" id="line-766"><code>	if j+bits &gt; ptrBits {</code></span>
<span class="codeline" id="line-767"><code>		// Two reads.</code></span>
<span class="codeline" id="line-768"><code>		bits0 := ptrBits - j</code></span>
<span class="codeline" id="line-769"><code>		bits1 := bits - bits0</code></span>
<span class="codeline" id="line-770"><code>		read = *word0 &gt;&gt; j</code></span>
<span class="codeline" id="line-771"><code>		read |= (*word1 &amp; ((1 &lt;&lt; bits1) - 1)) &lt;&lt; bits0</code></span>
<span class="codeline" id="line-772"><code>	} else {</code></span>
<span class="codeline" id="line-773"><code>		// One read.</code></span>
<span class="codeline" id="line-774"><code>		read = (*word0 &gt;&gt; j) &amp; ((1 &lt;&lt; bits) - 1)</code></span>
<span class="codeline" id="line-775"><code>	}</code></span>
<span class="codeline" id="line-776"><code>	return read</code></span>
<span class="codeline" id="line-777"><code>}</code></span>
<span class="codeline" id="line-778"><code></code></span>
<span class="codeline" id="line-779"><code>// writeHeapBitsSmall writes the heap bits for small objects whose ptr/scalar data is</code></span>
<span class="codeline" id="line-780"><code>// stored as a bitmap at the end of the span.</code></span>
<span class="codeline" id="line-781"><code>//</code></span>
<span class="codeline" id="line-782"><code>// Assumes dataSize is &lt;= ptrBits*goarch.PtrSize. x must be a pointer into the span.</code></span>
<span class="codeline" id="line-783"><code>// heapBitsInSpan(dataSize) must be true. dataSize must be &gt;= typ.Size_.</code></span>
<span class="codeline" id="line-784"><code>//</code></span>
<span class="codeline" id="line-785"><code>//go:nosplit</code></span>
<span class="codeline" id="line-786"><code>func (span *mspan) writeHeapBitsSmall(x, dataSize uintptr, typ *_type) (scanSize uintptr) {</code></span>
<span class="codeline" id="line-787"><code>	// The objects here are always really small, so a single load is sufficient.</code></span>
<span class="codeline" id="line-788"><code>	src0 := readUintptr(typ.GCData)</code></span>
<span class="codeline" id="line-789"><code></code></span>
<span class="codeline" id="line-790"><code>	// Create repetitions of the bitmap if we have a small array.</code></span>
<span class="codeline" id="line-791"><code>	bits := span.elemsize / goarch.PtrSize</code></span>
<span class="codeline" id="line-792"><code>	scanSize = typ.PtrBytes</code></span>
<span class="codeline" id="line-793"><code>	src := src0</code></span>
<span class="codeline" id="line-794"><code>	switch typ.Size_ {</code></span>
<span class="codeline" id="line-795"><code>	case goarch.PtrSize:</code></span>
<span class="codeline" id="line-796"><code>		src = (1 &lt;&lt; (dataSize / goarch.PtrSize)) - 1</code></span>
<span class="codeline" id="line-797"><code>	default:</code></span>
<span class="codeline" id="line-798"><code>		for i := typ.Size_; i &lt; dataSize; i += typ.Size_ {</code></span>
<span class="codeline" id="line-799"><code>			src |= src0 &lt;&lt; (i / goarch.PtrSize)</code></span>
<span class="codeline" id="line-800"><code>			scanSize += typ.Size_</code></span>
<span class="codeline" id="line-801"><code>		}</code></span>
<span class="codeline" id="line-802"><code>	}</code></span>
<span class="codeline" id="line-803"><code></code></span>
<span class="codeline" id="line-804"><code>	// Since we're never writing more than one uintptr's worth of bits, we're either going</code></span>
<span class="codeline" id="line-805"><code>	// to do one or two writes.</code></span>
<span class="codeline" id="line-806"><code>	dst := span.heapBits()</code></span>
<span class="codeline" id="line-807"><code>	o := (x - span.base()) / goarch.PtrSize</code></span>
<span class="codeline" id="line-808"><code>	i := o / ptrBits</code></span>
<span class="codeline" id="line-809"><code>	j := o % ptrBits</code></span>
<span class="codeline" id="line-810"><code>	if j+bits &gt; ptrBits {</code></span>
<span class="codeline" id="line-811"><code>		// Two writes.</code></span>
<span class="codeline" id="line-812"><code>		bits0 := ptrBits - j</code></span>
<span class="codeline" id="line-813"><code>		bits1 := bits - bits0</code></span>
<span class="codeline" id="line-814"><code>		dst[i+0] = dst[i+0]&amp;(^uintptr(0)&gt;&gt;bits0) | (src &lt;&lt; j)</code></span>
<span class="codeline" id="line-815"><code>		dst[i+1] = dst[i+1]&amp;^((1&lt;&lt;bits1)-1) | (src &gt;&gt; bits0)</code></span>
<span class="codeline" id="line-816"><code>	} else {</code></span>
<span class="codeline" id="line-817"><code>		// One write.</code></span>
<span class="codeline" id="line-818"><code>		dst[i] = (dst[i] &amp;^ (((1 &lt;&lt; bits) - 1) &lt;&lt; j)) | (src &lt;&lt; j)</code></span>
<span class="codeline" id="line-819"><code>	}</code></span>
<span class="codeline" id="line-820"><code></code></span>
<span class="codeline" id="line-821"><code>	const doubleCheck = false</code></span>
<span class="codeline" id="line-822"><code>	if doubleCheck {</code></span>
<span class="codeline" id="line-823"><code>		srcRead := span.heapBitsSmallForAddr(x)</code></span>
<span class="codeline" id="line-824"><code>		if srcRead != src {</code></span>
<span class="codeline" id="line-825"><code>			print("runtime: x=", hex(x), " i=", i, " j=", j, " bits=", bits, "\n")</code></span>
<span class="codeline" id="line-826"><code>			print("runtime: dataSize=", dataSize, " typ.Size_=", typ.Size_, " typ.PtrBytes=", typ.PtrBytes, "\n")</code></span>
<span class="codeline" id="line-827"><code>			print("runtime: src0=", hex(src0), " src=", hex(src), " srcRead=", hex(srcRead), "\n")</code></span>
<span class="codeline" id="line-828"><code>			throw("bad pointer bits written for small object")</code></span>
<span class="codeline" id="line-829"><code>		}</code></span>
<span class="codeline" id="line-830"><code>	}</code></span>
<span class="codeline" id="line-831"><code>	return</code></span>
<span class="codeline" id="line-832"><code>}</code></span>
<span class="codeline" id="line-833"><code></code></span>
<span class="codeline" id="line-834"><code>// For !goexperiment.AllocHeaders.</code></span>
<span class="codeline" id="line-835"><code>func heapBitsSetType(x, size, dataSize uintptr, typ *_type) {</code></span>
<span class="codeline" id="line-836"><code>}</code></span>
<span class="codeline" id="line-837"><code></code></span>
<span class="codeline" id="line-838"><code>// heapSetType records that the new allocation [x, x+size)</code></span>
<span class="codeline" id="line-839"><code>// holds in [x, x+dataSize) one or more values of type typ.</code></span>
<span class="codeline" id="line-840"><code>// (The number of values is given by dataSize / typ.Size.)</code></span>
<span class="codeline" id="line-841"><code>// If dataSize &lt; size, the fragment [x+dataSize, x+size) is</code></span>
<span class="codeline" id="line-842"><code>// recorded as non-pointer data.</code></span>
<span class="codeline" id="line-843"><code>// It is known that the type has pointers somewhere;</code></span>
<span class="codeline" id="line-844"><code>// malloc does not call heapSetType when there are no pointers.</code></span>
<span class="codeline" id="line-845"><code>//</code></span>
<span class="codeline" id="line-846"><code>// There can be read-write races between heapSetType and things</code></span>
<span class="codeline" id="line-847"><code>// that read the heap metadata like scanobject. However, since</code></span>
<span class="codeline" id="line-848"><code>// heapSetType is only used for objects that have not yet been</code></span>
<span class="codeline" id="line-849"><code>// made reachable, readers will ignore bits being modified by this</code></span>
<span class="codeline" id="line-850"><code>// function. This does mean this function cannot transiently modify</code></span>
<span class="codeline" id="line-851"><code>// shared memory that belongs to neighboring objects. Also, on weakly-ordered</code></span>
<span class="codeline" id="line-852"><code>// machines, callers must execute a store/store (publication) barrier</code></span>
<span class="codeline" id="line-853"><code>// between calling this function and making the object reachable.</code></span>
<span class="codeline" id="line-854"><code>func heapSetType(x, dataSize uintptr, typ *_type, header **_type, span *mspan) (scanSize uintptr) {</code></span>
<span class="codeline" id="line-855"><code>	const doubleCheck = false</code></span>
<span class="codeline" id="line-856"><code></code></span>
<span class="codeline" id="line-857"><code>	gctyp := typ</code></span>
<span class="codeline" id="line-858"><code>	if header == nil {</code></span>
<span class="codeline" id="line-859"><code>		if doubleCheck &amp;&amp; (!heapBitsInSpan(dataSize) || !heapBitsInSpan(span.elemsize)) {</code></span>
<span class="codeline" id="line-860"><code>			throw("tried to write heap bits, but no heap bits in span")</code></span>
<span class="codeline" id="line-861"><code>		}</code></span>
<span class="codeline" id="line-862"><code>		// Handle the case where we have no malloc header.</code></span>
<span class="codeline" id="line-863"><code>		scanSize = span.writeHeapBitsSmall(x, dataSize, typ)</code></span>
<span class="codeline" id="line-864"><code>	} else {</code></span>
<span class="codeline" id="line-865"><code>		if typ.Kind_&amp;kindGCProg != 0 {</code></span>
<span class="codeline" id="line-866"><code>			// Allocate space to unroll the gcprog. This space will consist of</code></span>
<span class="codeline" id="line-867"><code>			// a dummy _type value and the unrolled gcprog. The dummy _type will</code></span>
<span class="codeline" id="line-868"><code>			// refer to the bitmap, and the mspan will refer to the dummy _type.</code></span>
<span class="codeline" id="line-869"><code>			if span.spanclass.sizeclass() != 0 {</code></span>
<span class="codeline" id="line-870"><code>				throw("GCProg for type that isn't large")</code></span>
<span class="codeline" id="line-871"><code>			}</code></span>
<span class="codeline" id="line-872"><code>			spaceNeeded := alignUp(unsafe.Sizeof(_type{}), goarch.PtrSize)</code></span>
<span class="codeline" id="line-873"><code>			heapBitsOff := spaceNeeded</code></span>
<span class="codeline" id="line-874"><code>			spaceNeeded += alignUp(typ.PtrBytes/goarch.PtrSize/8, goarch.PtrSize)</code></span>
<span class="codeline" id="line-875"><code>			npages := alignUp(spaceNeeded, pageSize) / pageSize</code></span>
<span class="codeline" id="line-876"><code>			var progSpan *mspan</code></span>
<span class="codeline" id="line-877"><code>			systemstack(func() {</code></span>
<span class="codeline" id="line-878"><code>				progSpan = mheap_.allocManual(npages, spanAllocPtrScalarBits)</code></span>
<span class="codeline" id="line-879"><code>				memclrNoHeapPointers(unsafe.Pointer(progSpan.base()), progSpan.npages*pageSize)</code></span>
<span class="codeline" id="line-880"><code>			})</code></span>
<span class="codeline" id="line-881"><code>			// Write a dummy _type in the new space.</code></span>
<span class="codeline" id="line-882"><code>			//</code></span>
<span class="codeline" id="line-883"><code>			// We only need to write size, PtrBytes, and GCData, since that's all</code></span>
<span class="codeline" id="line-884"><code>			// the GC cares about.</code></span>
<span class="codeline" id="line-885"><code>			gctyp = (*_type)(unsafe.Pointer(progSpan.base()))</code></span>
<span class="codeline" id="line-886"><code>			gctyp.Size_ = typ.Size_</code></span>
<span class="codeline" id="line-887"><code>			gctyp.PtrBytes = typ.PtrBytes</code></span>
<span class="codeline" id="line-888"><code>			gctyp.GCData = (*byte)(add(unsafe.Pointer(progSpan.base()), heapBitsOff))</code></span>
<span class="codeline" id="line-889"><code>			gctyp.TFlag = abi.TFlagUnrolledBitmap</code></span>
<span class="codeline" id="line-890"><code></code></span>
<span class="codeline" id="line-891"><code>			// Expand the GC program into space reserved at the end of the new span.</code></span>
<span class="codeline" id="line-892"><code>			runGCProg(addb(typ.GCData, 4), gctyp.GCData)</code></span>
<span class="codeline" id="line-893"><code>		}</code></span>
<span class="codeline" id="line-894"><code></code></span>
<span class="codeline" id="line-895"><code>		// Write out the header.</code></span>
<span class="codeline" id="line-896"><code>		*header = gctyp</code></span>
<span class="codeline" id="line-897"><code>		scanSize = span.elemsize</code></span>
<span class="codeline" id="line-898"><code>	}</code></span>
<span class="codeline" id="line-899"><code></code></span>
<span class="codeline" id="line-900"><code>	if doubleCheck {</code></span>
<span class="codeline" id="line-901"><code>		doubleCheckHeapPointers(x, dataSize, gctyp, header, span)</code></span>
<span class="codeline" id="line-902"><code></code></span>
<span class="codeline" id="line-903"><code>		// To exercise the less common path more often, generate</code></span>
<span class="codeline" id="line-904"><code>		// a random interior pointer and make sure iterating from</code></span>
<span class="codeline" id="line-905"><code>		// that point works correctly too.</code></span>
<span class="codeline" id="line-906"><code>		maxIterBytes := span.elemsize</code></span>
<span class="codeline" id="line-907"><code>		if header == nil {</code></span>
<span class="codeline" id="line-908"><code>			maxIterBytes = dataSize</code></span>
<span class="codeline" id="line-909"><code>		}</code></span>
<span class="codeline" id="line-910"><code>		off := alignUp(uintptr(cheaprand())%dataSize, goarch.PtrSize)</code></span>
<span class="codeline" id="line-911"><code>		size := dataSize - off</code></span>
<span class="codeline" id="line-912"><code>		if size == 0 {</code></span>
<span class="codeline" id="line-913"><code>			off -= goarch.PtrSize</code></span>
<span class="codeline" id="line-914"><code>			size += goarch.PtrSize</code></span>
<span class="codeline" id="line-915"><code>		}</code></span>
<span class="codeline" id="line-916"><code>		interior := x + off</code></span>
<span class="codeline" id="line-917"><code>		size -= alignDown(uintptr(cheaprand())%size, goarch.PtrSize)</code></span>
<span class="codeline" id="line-918"><code>		if size == 0 {</code></span>
<span class="codeline" id="line-919"><code>			size = goarch.PtrSize</code></span>
<span class="codeline" id="line-920"><code>		}</code></span>
<span class="codeline" id="line-921"><code>		// Round up the type to the size of the type.</code></span>
<span class="codeline" id="line-922"><code>		size = (size + gctyp.Size_ - 1) / gctyp.Size_ * gctyp.Size_</code></span>
<span class="codeline" id="line-923"><code>		if interior+size &gt; x+maxIterBytes {</code></span>
<span class="codeline" id="line-924"><code>			size = x + maxIterBytes - interior</code></span>
<span class="codeline" id="line-925"><code>		}</code></span>
<span class="codeline" id="line-926"><code>		doubleCheckHeapPointersInterior(x, interior, size, dataSize, gctyp, header, span)</code></span>
<span class="codeline" id="line-927"><code>	}</code></span>
<span class="codeline" id="line-928"><code>	return</code></span>
<span class="codeline" id="line-929"><code>}</code></span>
<span class="codeline" id="line-930"><code></code></span>
<span class="codeline" id="line-931"><code>func doubleCheckHeapPointers(x, dataSize uintptr, typ *_type, header **_type, span *mspan) {</code></span>
<span class="codeline" id="line-932"><code>	// Check that scanning the full object works.</code></span>
<span class="codeline" id="line-933"><code>	tp := span.typePointersOfUnchecked(span.objBase(x))</code></span>
<span class="codeline" id="line-934"><code>	maxIterBytes := span.elemsize</code></span>
<span class="codeline" id="line-935"><code>	if header == nil {</code></span>
<span class="codeline" id="line-936"><code>		maxIterBytes = dataSize</code></span>
<span class="codeline" id="line-937"><code>	}</code></span>
<span class="codeline" id="line-938"><code>	bad := false</code></span>
<span class="codeline" id="line-939"><code>	for i := uintptr(0); i &lt; maxIterBytes; i += goarch.PtrSize {</code></span>
<span class="codeline" id="line-940"><code>		// Compute the pointer bit we want at offset i.</code></span>
<span class="codeline" id="line-941"><code>		want := false</code></span>
<span class="codeline" id="line-942"><code>		if i &lt; span.elemsize {</code></span>
<span class="codeline" id="line-943"><code>			off := i % typ.Size_</code></span>
<span class="codeline" id="line-944"><code>			if off &lt; typ.PtrBytes {</code></span>
<span class="codeline" id="line-945"><code>				j := off / goarch.PtrSize</code></span>
<span class="codeline" id="line-946"><code>				want = *addb(typ.GCData, j/8)&gt;&gt;(j%8)&amp;1 != 0</code></span>
<span class="codeline" id="line-947"><code>			}</code></span>
<span class="codeline" id="line-948"><code>		}</code></span>
<span class="codeline" id="line-949"><code>		if want {</code></span>
<span class="codeline" id="line-950"><code>			var addr uintptr</code></span>
<span class="codeline" id="line-951"><code>			tp, addr = tp.next(x + span.elemsize)</code></span>
<span class="codeline" id="line-952"><code>			if addr == 0 {</code></span>
<span class="codeline" id="line-953"><code>				println("runtime: found bad iterator")</code></span>
<span class="codeline" id="line-954"><code>			}</code></span>
<span class="codeline" id="line-955"><code>			if addr != x+i {</code></span>
<span class="codeline" id="line-956"><code>				print("runtime: addr=", hex(addr), " x+i=", hex(x+i), "\n")</code></span>
<span class="codeline" id="line-957"><code>				bad = true</code></span>
<span class="codeline" id="line-958"><code>			}</code></span>
<span class="codeline" id="line-959"><code>		}</code></span>
<span class="codeline" id="line-960"><code>	}</code></span>
<span class="codeline" id="line-961"><code>	if !bad {</code></span>
<span class="codeline" id="line-962"><code>		var addr uintptr</code></span>
<span class="codeline" id="line-963"><code>		tp, addr = tp.next(x + span.elemsize)</code></span>
<span class="codeline" id="line-964"><code>		if addr == 0 {</code></span>
<span class="codeline" id="line-965"><code>			return</code></span>
<span class="codeline" id="line-966"><code>		}</code></span>
<span class="codeline" id="line-967"><code>		println("runtime: extra pointer:", hex(addr))</code></span>
<span class="codeline" id="line-968"><code>	}</code></span>
<span class="codeline" id="line-969"><code>	print("runtime: hasHeader=", header != nil, " typ.Size_=", typ.Size_, " hasGCProg=", typ.Kind_&amp;kindGCProg != 0, "\n")</code></span>
<span class="codeline" id="line-970"><code>	print("runtime: x=", hex(x), " dataSize=", dataSize, " elemsize=", span.elemsize, "\n")</code></span>
<span class="codeline" id="line-971"><code>	print("runtime: typ=", unsafe.Pointer(typ), " typ.PtrBytes=", typ.PtrBytes, "\n")</code></span>
<span class="codeline" id="line-972"><code>	print("runtime: limit=", hex(x+span.elemsize), "\n")</code></span>
<span class="codeline" id="line-973"><code>	tp = span.typePointersOfUnchecked(x)</code></span>
<span class="codeline" id="line-974"><code>	dumpTypePointers(tp)</code></span>
<span class="codeline" id="line-975"><code>	for {</code></span>
<span class="codeline" id="line-976"><code>		var addr uintptr</code></span>
<span class="codeline" id="line-977"><code>		if tp, addr = tp.next(x + span.elemsize); addr == 0 {</code></span>
<span class="codeline" id="line-978"><code>			println("runtime: would've stopped here")</code></span>
<span class="codeline" id="line-979"><code>			dumpTypePointers(tp)</code></span>
<span class="codeline" id="line-980"><code>			break</code></span>
<span class="codeline" id="line-981"><code>		}</code></span>
<span class="codeline" id="line-982"><code>		print("runtime: addr=", hex(addr), "\n")</code></span>
<span class="codeline" id="line-983"><code>		dumpTypePointers(tp)</code></span>
<span class="codeline" id="line-984"><code>	}</code></span>
<span class="codeline" id="line-985"><code>	throw("heapSetType: pointer entry not correct")</code></span>
<span class="codeline" id="line-986"><code>}</code></span>
<span class="codeline" id="line-987"><code></code></span>
<span class="codeline" id="line-988"><code>func doubleCheckHeapPointersInterior(x, interior, size, dataSize uintptr, typ *_type, header **_type, span *mspan) {</code></span>
<span class="codeline" id="line-989"><code>	bad := false</code></span>
<span class="codeline" id="line-990"><code>	if interior &lt; x {</code></span>
<span class="codeline" id="line-991"><code>		print("runtime: interior=", hex(interior), " x=", hex(x), "\n")</code></span>
<span class="codeline" id="line-992"><code>		throw("found bad interior pointer")</code></span>
<span class="codeline" id="line-993"><code>	}</code></span>
<span class="codeline" id="line-994"><code>	off := interior - x</code></span>
<span class="codeline" id="line-995"><code>	tp := span.typePointersOf(interior, size)</code></span>
<span class="codeline" id="line-996"><code>	for i := off; i &lt; off+size; i += goarch.PtrSize {</code></span>
<span class="codeline" id="line-997"><code>		// Compute the pointer bit we want at offset i.</code></span>
<span class="codeline" id="line-998"><code>		want := false</code></span>
<span class="codeline" id="line-999"><code>		if i &lt; span.elemsize {</code></span>
<span class="codeline" id="line-1000"><code>			off := i % typ.Size_</code></span>
<span class="codeline" id="line-1001"><code>			if off &lt; typ.PtrBytes {</code></span>
<span class="codeline" id="line-1002"><code>				j := off / goarch.PtrSize</code></span>
<span class="codeline" id="line-1003"><code>				want = *addb(typ.GCData, j/8)&gt;&gt;(j%8)&amp;1 != 0</code></span>
<span class="codeline" id="line-1004"><code>			}</code></span>
<span class="codeline" id="line-1005"><code>		}</code></span>
<span class="codeline" id="line-1006"><code>		if want {</code></span>
<span class="codeline" id="line-1007"><code>			var addr uintptr</code></span>
<span class="codeline" id="line-1008"><code>			tp, addr = tp.next(interior + size)</code></span>
<span class="codeline" id="line-1009"><code>			if addr == 0 {</code></span>
<span class="codeline" id="line-1010"><code>				println("runtime: found bad iterator")</code></span>
<span class="codeline" id="line-1011"><code>				bad = true</code></span>
<span class="codeline" id="line-1012"><code>			}</code></span>
<span class="codeline" id="line-1013"><code>			if addr != x+i {</code></span>
<span class="codeline" id="line-1014"><code>				print("runtime: addr=", hex(addr), " x+i=", hex(x+i), "\n")</code></span>
<span class="codeline" id="line-1015"><code>				bad = true</code></span>
<span class="codeline" id="line-1016"><code>			}</code></span>
<span class="codeline" id="line-1017"><code>		}</code></span>
<span class="codeline" id="line-1018"><code>	}</code></span>
<span class="codeline" id="line-1019"><code>	if !bad {</code></span>
<span class="codeline" id="line-1020"><code>		var addr uintptr</code></span>
<span class="codeline" id="line-1021"><code>		tp, addr = tp.next(interior + size)</code></span>
<span class="codeline" id="line-1022"><code>		if addr == 0 {</code></span>
<span class="codeline" id="line-1023"><code>			return</code></span>
<span class="codeline" id="line-1024"><code>		}</code></span>
<span class="codeline" id="line-1025"><code>		println("runtime: extra pointer:", hex(addr))</code></span>
<span class="codeline" id="line-1026"><code>	}</code></span>
<span class="codeline" id="line-1027"><code>	print("runtime: hasHeader=", header != nil, " typ.Size_=", typ.Size_, "\n")</code></span>
<span class="codeline" id="line-1028"><code>	print("runtime: x=", hex(x), " dataSize=", dataSize, " elemsize=", span.elemsize, " interior=", hex(interior), " size=", size, "\n")</code></span>
<span class="codeline" id="line-1029"><code>	print("runtime: limit=", hex(interior+size), "\n")</code></span>
<span class="codeline" id="line-1030"><code>	tp = span.typePointersOf(interior, size)</code></span>
<span class="codeline" id="line-1031"><code>	dumpTypePointers(tp)</code></span>
<span class="codeline" id="line-1032"><code>	for {</code></span>
<span class="codeline" id="line-1033"><code>		var addr uintptr</code></span>
<span class="codeline" id="line-1034"><code>		if tp, addr = tp.next(interior + size); addr == 0 {</code></span>
<span class="codeline" id="line-1035"><code>			println("runtime: would've stopped here")</code></span>
<span class="codeline" id="line-1036"><code>			dumpTypePointers(tp)</code></span>
<span class="codeline" id="line-1037"><code>			break</code></span>
<span class="codeline" id="line-1038"><code>		}</code></span>
<span class="codeline" id="line-1039"><code>		print("runtime: addr=", hex(addr), "\n")</code></span>
<span class="codeline" id="line-1040"><code>		dumpTypePointers(tp)</code></span>
<span class="codeline" id="line-1041"><code>	}</code></span>
<span class="codeline" id="line-1042"><code></code></span>
<span class="codeline" id="line-1043"><code>	print("runtime: want: ")</code></span>
<span class="codeline" id="line-1044"><code>	for i := off; i &lt; off+size; i += goarch.PtrSize {</code></span>
<span class="codeline" id="line-1045"><code>		// Compute the pointer bit we want at offset i.</code></span>
<span class="codeline" id="line-1046"><code>		want := false</code></span>
<span class="codeline" id="line-1047"><code>		if i &lt; dataSize {</code></span>
<span class="codeline" id="line-1048"><code>			off := i % typ.Size_</code></span>
<span class="codeline" id="line-1049"><code>			if off &lt; typ.PtrBytes {</code></span>
<span class="codeline" id="line-1050"><code>				j := off / goarch.PtrSize</code></span>
<span class="codeline" id="line-1051"><code>				want = *addb(typ.GCData, j/8)&gt;&gt;(j%8)&amp;1 != 0</code></span>
<span class="codeline" id="line-1052"><code>			}</code></span>
<span class="codeline" id="line-1053"><code>		}</code></span>
<span class="codeline" id="line-1054"><code>		if want {</code></span>
<span class="codeline" id="line-1055"><code>			print("1")</code></span>
<span class="codeline" id="line-1056"><code>		} else {</code></span>
<span class="codeline" id="line-1057"><code>			print("0")</code></span>
<span class="codeline" id="line-1058"><code>		}</code></span>
<span class="codeline" id="line-1059"><code>	}</code></span>
<span class="codeline" id="line-1060"><code>	println()</code></span>
<span class="codeline" id="line-1061"><code></code></span>
<span class="codeline" id="line-1062"><code>	throw("heapSetType: pointer entry not correct")</code></span>
<span class="codeline" id="line-1063"><code>}</code></span>
<span class="codeline" id="line-1064"><code></code></span>
<span class="codeline" id="line-1065"><code>//go:nosplit</code></span>
<span class="codeline" id="line-1066"><code>func doubleCheckTypePointersOfType(s *mspan, typ *_type, addr, size uintptr) {</code></span>
<span class="codeline" id="line-1067"><code>	if typ == nil || typ.Kind_&amp;kindGCProg != 0 {</code></span>
<span class="codeline" id="line-1068"><code>		return</code></span>
<span class="codeline" id="line-1069"><code>	}</code></span>
<span class="codeline" id="line-1070"><code>	if typ.Kind_&amp;kindMask == kindInterface {</code></span>
<span class="codeline" id="line-1071"><code>		// Interfaces are unfortunately inconsistently handled</code></span>
<span class="codeline" id="line-1072"><code>		// when it comes to the type pointer, so it's easy to</code></span>
<span class="codeline" id="line-1073"><code>		// produce a lot of false positives here.</code></span>
<span class="codeline" id="line-1074"><code>		return</code></span>
<span class="codeline" id="line-1075"><code>	}</code></span>
<span class="codeline" id="line-1076"><code>	tp0 := s.typePointersOfType(typ, addr)</code></span>
<span class="codeline" id="line-1077"><code>	tp1 := s.typePointersOf(addr, size)</code></span>
<span class="codeline" id="line-1078"><code>	failed := false</code></span>
<span class="codeline" id="line-1079"><code>	for {</code></span>
<span class="codeline" id="line-1080"><code>		var addr0, addr1 uintptr</code></span>
<span class="codeline" id="line-1081"><code>		tp0, addr0 = tp0.next(addr + size)</code></span>
<span class="codeline" id="line-1082"><code>		tp1, addr1 = tp1.next(addr + size)</code></span>
<span class="codeline" id="line-1083"><code>		if addr0 != addr1 {</code></span>
<span class="codeline" id="line-1084"><code>			failed = true</code></span>
<span class="codeline" id="line-1085"><code>			break</code></span>
<span class="codeline" id="line-1086"><code>		}</code></span>
<span class="codeline" id="line-1087"><code>		if addr0 == 0 {</code></span>
<span class="codeline" id="line-1088"><code>			break</code></span>
<span class="codeline" id="line-1089"><code>		}</code></span>
<span class="codeline" id="line-1090"><code>	}</code></span>
<span class="codeline" id="line-1091"><code>	if failed {</code></span>
<span class="codeline" id="line-1092"><code>		tp0 := s.typePointersOfType(typ, addr)</code></span>
<span class="codeline" id="line-1093"><code>		tp1 := s.typePointersOf(addr, size)</code></span>
<span class="codeline" id="line-1094"><code>		print("runtime: addr=", hex(addr), " size=", size, "\n")</code></span>
<span class="codeline" id="line-1095"><code>		print("runtime: type=", toRType(typ).string(), "\n")</code></span>
<span class="codeline" id="line-1096"><code>		dumpTypePointers(tp0)</code></span>
<span class="codeline" id="line-1097"><code>		dumpTypePointers(tp1)</code></span>
<span class="codeline" id="line-1098"><code>		for {</code></span>
<span class="codeline" id="line-1099"><code>			var addr0, addr1 uintptr</code></span>
<span class="codeline" id="line-1100"><code>			tp0, addr0 = tp0.next(addr + size)</code></span>
<span class="codeline" id="line-1101"><code>			tp1, addr1 = tp1.next(addr + size)</code></span>
<span class="codeline" id="line-1102"><code>			print("runtime: ", hex(addr0), " ", hex(addr1), "\n")</code></span>
<span class="codeline" id="line-1103"><code>			if addr0 == 0 &amp;&amp; addr1 == 0 {</code></span>
<span class="codeline" id="line-1104"><code>				break</code></span>
<span class="codeline" id="line-1105"><code>			}</code></span>
<span class="codeline" id="line-1106"><code>		}</code></span>
<span class="codeline" id="line-1107"><code>		throw("mismatch between typePointersOfType and typePointersOf")</code></span>
<span class="codeline" id="line-1108"><code>	}</code></span>
<span class="codeline" id="line-1109"><code>}</code></span>
<span class="codeline" id="line-1110"><code></code></span>
<span class="codeline" id="line-1111"><code>func dumpTypePointers(tp typePointers) {</code></span>
<span class="codeline" id="line-1112"><code>	print("runtime: tp.elem=", hex(tp.elem), " tp.typ=", unsafe.Pointer(tp.typ), "\n")</code></span>
<span class="codeline" id="line-1113"><code>	print("runtime: tp.addr=", hex(tp.addr), " tp.mask=")</code></span>
<span class="codeline" id="line-1114"><code>	for i := uintptr(0); i &lt; ptrBits; i++ {</code></span>
<span class="codeline" id="line-1115"><code>		if tp.mask&amp;(uintptr(1)&lt;&lt;i) != 0 {</code></span>
<span class="codeline" id="line-1116"><code>			print("1")</code></span>
<span class="codeline" id="line-1117"><code>		} else {</code></span>
<span class="codeline" id="line-1118"><code>			print("0")</code></span>
<span class="codeline" id="line-1119"><code>		}</code></span>
<span class="codeline" id="line-1120"><code>	}</code></span>
<span class="codeline" id="line-1121"><code>	println()</code></span>
<span class="codeline" id="line-1122"><code>}</code></span>
<span class="codeline" id="line-1123"><code></code></span>
<span class="codeline" id="line-1124"><code>// Testing.</code></span>
<span class="codeline" id="line-1125"><code></code></span>
<span class="codeline" id="line-1126"><code>// Returns GC type info for the pointer stored in ep for testing.</code></span>
<span class="codeline" id="line-1127"><code>// If ep points to the stack, only static live information will be returned</code></span>
<span class="codeline" id="line-1128"><code>// (i.e. not for objects which are only dynamically live stack objects).</code></span>
<span class="codeline" id="line-1129"><code>func getgcmask(ep any) (mask []byte) {</code></span>
<span class="codeline" id="line-1130"><code>	e := *efaceOf(&amp;ep)</code></span>
<span class="codeline" id="line-1131"><code>	p := e.data</code></span>
<span class="codeline" id="line-1132"><code>	t := e._type</code></span>
<span class="codeline" id="line-1133"><code></code></span>
<span class="codeline" id="line-1134"><code>	var et *_type</code></span>
<span class="codeline" id="line-1135"><code>	if t.Kind_&amp;kindMask != kindPtr {</code></span>
<span class="codeline" id="line-1136"><code>		throw("bad argument to getgcmask: expected type to be a pointer to the value type whose mask is being queried")</code></span>
<span class="codeline" id="line-1137"><code>	}</code></span>
<span class="codeline" id="line-1138"><code>	et = (*ptrtype)(unsafe.Pointer(t)).Elem</code></span>
<span class="codeline" id="line-1139"><code></code></span>
<span class="codeline" id="line-1140"><code>	// data or bss</code></span>
<span class="codeline" id="line-1141"><code>	for _, datap := range activeModules() {</code></span>
<span class="codeline" id="line-1142"><code>		// data</code></span>
<span class="codeline" id="line-1143"><code>		if datap.data &lt;= uintptr(p) &amp;&amp; uintptr(p) &lt; datap.edata {</code></span>
<span class="codeline" id="line-1144"><code>			bitmap := datap.gcdatamask.bytedata</code></span>
<span class="codeline" id="line-1145"><code>			n := et.Size_</code></span>
<span class="codeline" id="line-1146"><code>			mask = make([]byte, n/goarch.PtrSize)</code></span>
<span class="codeline" id="line-1147"><code>			for i := uintptr(0); i &lt; n; i += goarch.PtrSize {</code></span>
<span class="codeline" id="line-1148"><code>				off := (uintptr(p) + i - datap.data) / goarch.PtrSize</code></span>
<span class="codeline" id="line-1149"><code>				mask[i/goarch.PtrSize] = (*addb(bitmap, off/8) &gt;&gt; (off % 8)) &amp; 1</code></span>
<span class="codeline" id="line-1150"><code>			}</code></span>
<span class="codeline" id="line-1151"><code>			return</code></span>
<span class="codeline" id="line-1152"><code>		}</code></span>
<span class="codeline" id="line-1153"><code></code></span>
<span class="codeline" id="line-1154"><code>		// bss</code></span>
<span class="codeline" id="line-1155"><code>		if datap.bss &lt;= uintptr(p) &amp;&amp; uintptr(p) &lt; datap.ebss {</code></span>
<span class="codeline" id="line-1156"><code>			bitmap := datap.gcbssmask.bytedata</code></span>
<span class="codeline" id="line-1157"><code>			n := et.Size_</code></span>
<span class="codeline" id="line-1158"><code>			mask = make([]byte, n/goarch.PtrSize)</code></span>
<span class="codeline" id="line-1159"><code>			for i := uintptr(0); i &lt; n; i += goarch.PtrSize {</code></span>
<span class="codeline" id="line-1160"><code>				off := (uintptr(p) + i - datap.bss) / goarch.PtrSize</code></span>
<span class="codeline" id="line-1161"><code>				mask[i/goarch.PtrSize] = (*addb(bitmap, off/8) &gt;&gt; (off % 8)) &amp; 1</code></span>
<span class="codeline" id="line-1162"><code>			}</code></span>
<span class="codeline" id="line-1163"><code>			return</code></span>
<span class="codeline" id="line-1164"><code>		}</code></span>
<span class="codeline" id="line-1165"><code>	}</code></span>
<span class="codeline" id="line-1166"><code></code></span>
<span class="codeline" id="line-1167"><code>	// heap</code></span>
<span class="codeline" id="line-1168"><code>	if base, s, _ := findObject(uintptr(p), 0, 0); base != 0 {</code></span>
<span class="codeline" id="line-1169"><code>		if s.spanclass.noscan() {</code></span>
<span class="codeline" id="line-1170"><code>			return nil</code></span>
<span class="codeline" id="line-1171"><code>		}</code></span>
<span class="codeline" id="line-1172"><code>		limit := base + s.elemsize</code></span>
<span class="codeline" id="line-1173"><code></code></span>
<span class="codeline" id="line-1174"><code>		// Move the base up to the iterator's start, because</code></span>
<span class="codeline" id="line-1175"><code>		// we want to hide evidence of a malloc header from the</code></span>
<span class="codeline" id="line-1176"><code>		// caller.</code></span>
<span class="codeline" id="line-1177"><code>		tp := s.typePointersOfUnchecked(base)</code></span>
<span class="codeline" id="line-1178"><code>		base = tp.addr</code></span>
<span class="codeline" id="line-1179"><code></code></span>
<span class="codeline" id="line-1180"><code>		// Unroll the full bitmap the GC would actually observe.</code></span>
<span class="codeline" id="line-1181"><code>		maskFromHeap := make([]byte, (limit-base)/goarch.PtrSize)</code></span>
<span class="codeline" id="line-1182"><code>		for {</code></span>
<span class="codeline" id="line-1183"><code>			var addr uintptr</code></span>
<span class="codeline" id="line-1184"><code>			if tp, addr = tp.next(limit); addr == 0 {</code></span>
<span class="codeline" id="line-1185"><code>				break</code></span>
<span class="codeline" id="line-1186"><code>			}</code></span>
<span class="codeline" id="line-1187"><code>			maskFromHeap[(addr-base)/goarch.PtrSize] = 1</code></span>
<span class="codeline" id="line-1188"><code>		}</code></span>
<span class="codeline" id="line-1189"><code></code></span>
<span class="codeline" id="line-1190"><code>		// Double-check that every part of the ptr/scalar we're not</code></span>
<span class="codeline" id="line-1191"><code>		// showing the caller is zeroed. This keeps us honest that</code></span>
<span class="codeline" id="line-1192"><code>		// that information is actually irrelevant.</code></span>
<span class="codeline" id="line-1193"><code>		for i := limit; i &lt; s.elemsize; i++ {</code></span>
<span class="codeline" id="line-1194"><code>			if *(*byte)(unsafe.Pointer(i)) != 0 {</code></span>
<span class="codeline" id="line-1195"><code>				throw("found non-zeroed tail of allocation")</code></span>
<span class="codeline" id="line-1196"><code>			}</code></span>
<span class="codeline" id="line-1197"><code>		}</code></span>
<span class="codeline" id="line-1198"><code></code></span>
<span class="codeline" id="line-1199"><code>		// Callers (and a check we're about to run) expects this mask</code></span>
<span class="codeline" id="line-1200"><code>		// to end at the last pointer.</code></span>
<span class="codeline" id="line-1201"><code>		for len(maskFromHeap) &gt; 0 &amp;&amp; maskFromHeap[len(maskFromHeap)-1] == 0 {</code></span>
<span class="codeline" id="line-1202"><code>			maskFromHeap = maskFromHeap[:len(maskFromHeap)-1]</code></span>
<span class="codeline" id="line-1203"><code>		}</code></span>
<span class="codeline" id="line-1204"><code></code></span>
<span class="codeline" id="line-1205"><code>		if et.Kind_&amp;kindGCProg == 0 {</code></span>
<span class="codeline" id="line-1206"><code>			// Unroll again, but this time from the type information.</code></span>
<span class="codeline" id="line-1207"><code>			maskFromType := make([]byte, (limit-base)/goarch.PtrSize)</code></span>
<span class="codeline" id="line-1208"><code>			tp = s.typePointersOfType(et, base)</code></span>
<span class="codeline" id="line-1209"><code>			for {</code></span>
<span class="codeline" id="line-1210"><code>				var addr uintptr</code></span>
<span class="codeline" id="line-1211"><code>				if tp, addr = tp.next(limit); addr == 0 {</code></span>
<span class="codeline" id="line-1212"><code>					break</code></span>
<span class="codeline" id="line-1213"><code>				}</code></span>
<span class="codeline" id="line-1214"><code>				maskFromType[(addr-base)/goarch.PtrSize] = 1</code></span>
<span class="codeline" id="line-1215"><code>			}</code></span>
<span class="codeline" id="line-1216"><code></code></span>
<span class="codeline" id="line-1217"><code>			// Validate that the prefix of maskFromType is equal to</code></span>
<span class="codeline" id="line-1218"><code>			// maskFromHeap. maskFromType may contain more pointers than</code></span>
<span class="codeline" id="line-1219"><code>			// maskFromHeap produces because maskFromHeap may be able to</code></span>
<span class="codeline" id="line-1220"><code>			// get exact type information for certain classes of objects.</code></span>
<span class="codeline" id="line-1221"><code>			// With maskFromType, we're always just tiling the type bitmap</code></span>
<span class="codeline" id="line-1222"><code>			// through to the elemsize.</code></span>
<span class="codeline" id="line-1223"><code>			//</code></span>
<span class="codeline" id="line-1224"><code>			// It's OK if maskFromType has pointers in elemsize that extend</code></span>
<span class="codeline" id="line-1225"><code>			// past the actual populated space; we checked above that all</code></span>
<span class="codeline" id="line-1226"><code>			// that space is zeroed, so just the GC will just see nil pointers.</code></span>
<span class="codeline" id="line-1227"><code>			differs := false</code></span>
<span class="codeline" id="line-1228"><code>			for i := range maskFromHeap {</code></span>
<span class="codeline" id="line-1229"><code>				if maskFromHeap[i] != maskFromType[i] {</code></span>
<span class="codeline" id="line-1230"><code>					differs = true</code></span>
<span class="codeline" id="line-1231"><code>					break</code></span>
<span class="codeline" id="line-1232"><code>				}</code></span>
<span class="codeline" id="line-1233"><code>			}</code></span>
<span class="codeline" id="line-1234"><code></code></span>
<span class="codeline" id="line-1235"><code>			if differs {</code></span>
<span class="codeline" id="line-1236"><code>				print("runtime: heap mask=")</code></span>
<span class="codeline" id="line-1237"><code>				for _, b := range maskFromHeap {</code></span>
<span class="codeline" id="line-1238"><code>					print(b)</code></span>
<span class="codeline" id="line-1239"><code>				}</code></span>
<span class="codeline" id="line-1240"><code>				println()</code></span>
<span class="codeline" id="line-1241"><code>				print("runtime: type mask=")</code></span>
<span class="codeline" id="line-1242"><code>				for _, b := range maskFromType {</code></span>
<span class="codeline" id="line-1243"><code>					print(b)</code></span>
<span class="codeline" id="line-1244"><code>				}</code></span>
<span class="codeline" id="line-1245"><code>				println()</code></span>
<span class="codeline" id="line-1246"><code>				print("runtime: type=", toRType(et).string(), "\n")</code></span>
<span class="codeline" id="line-1247"><code>				throw("found two different masks from two different methods")</code></span>
<span class="codeline" id="line-1248"><code>			}</code></span>
<span class="codeline" id="line-1249"><code>		}</code></span>
<span class="codeline" id="line-1250"><code></code></span>
<span class="codeline" id="line-1251"><code>		// Select the heap mask to return. We may not have a type mask.</code></span>
<span class="codeline" id="line-1252"><code>		mask = maskFromHeap</code></span>
<span class="codeline" id="line-1253"><code></code></span>
<span class="codeline" id="line-1254"><code>		// Make sure we keep ep alive. We may have stopped referencing</code></span>
<span class="codeline" id="line-1255"><code>		// ep's data pointer sometime before this point and it's possible</code></span>
<span class="codeline" id="line-1256"><code>		// for that memory to get freed.</code></span>
<span class="codeline" id="line-1257"><code>		KeepAlive(ep)</code></span>
<span class="codeline" id="line-1258"><code>		return</code></span>
<span class="codeline" id="line-1259"><code>	}</code></span>
<span class="codeline" id="line-1260"><code></code></span>
<span class="codeline" id="line-1261"><code>	// stack</code></span>
<span class="codeline" id="line-1262"><code>	if gp := getg(); gp.m.curg.stack.lo &lt;= uintptr(p) &amp;&amp; uintptr(p) &lt; gp.m.curg.stack.hi {</code></span>
<span class="codeline" id="line-1263"><code>		found := false</code></span>
<span class="codeline" id="line-1264"><code>		var u unwinder</code></span>
<span class="codeline" id="line-1265"><code>		for u.initAt(gp.m.curg.sched.pc, gp.m.curg.sched.sp, 0, gp.m.curg, 0); u.valid(); u.next() {</code></span>
<span class="codeline" id="line-1266"><code>			if u.frame.sp &lt;= uintptr(p) &amp;&amp; uintptr(p) &lt; u.frame.varp {</code></span>
<span class="codeline" id="line-1267"><code>				found = true</code></span>
<span class="codeline" id="line-1268"><code>				break</code></span>
<span class="codeline" id="line-1269"><code>			}</code></span>
<span class="codeline" id="line-1270"><code>		}</code></span>
<span class="codeline" id="line-1271"><code>		if found {</code></span>
<span class="codeline" id="line-1272"><code>			locals, _, _ := u.frame.getStackMap(false)</code></span>
<span class="codeline" id="line-1273"><code>			if locals.n == 0 {</code></span>
<span class="codeline" id="line-1274"><code>				return</code></span>
<span class="codeline" id="line-1275"><code>			}</code></span>
<span class="codeline" id="line-1276"><code>			size := uintptr(locals.n) * goarch.PtrSize</code></span>
<span class="codeline" id="line-1277"><code>			n := (*ptrtype)(unsafe.Pointer(t)).Elem.Size_</code></span>
<span class="codeline" id="line-1278"><code>			mask = make([]byte, n/goarch.PtrSize)</code></span>
<span class="codeline" id="line-1279"><code>			for i := uintptr(0); i &lt; n; i += goarch.PtrSize {</code></span>
<span class="codeline" id="line-1280"><code>				off := (uintptr(p) + i - u.frame.varp + size) / goarch.PtrSize</code></span>
<span class="codeline" id="line-1281"><code>				mask[i/goarch.PtrSize] = locals.ptrbit(off)</code></span>
<span class="codeline" id="line-1282"><code>			}</code></span>
<span class="codeline" id="line-1283"><code>		}</code></span>
<span class="codeline" id="line-1284"><code>		return</code></span>
<span class="codeline" id="line-1285"><code>	}</code></span>
<span class="codeline" id="line-1286"><code></code></span>
<span class="codeline" id="line-1287"><code>	// otherwise, not something the GC knows about.</code></span>
<span class="codeline" id="line-1288"><code>	// possibly read-only data, like malloc(0).</code></span>
<span class="codeline" id="line-1289"><code>	// must not have pointers</code></span>
<span class="codeline" id="line-1290"><code>	return</code></span>
<span class="codeline" id="line-1291"><code>}</code></span>
<span class="codeline" id="line-1292"><code></code></span>
<span class="codeline" id="line-1293"><code>// userArenaHeapBitsSetType is the equivalent of heapSetType but for</code></span>
<span class="codeline" id="line-1294"><code>// non-slice-backing-store Go values allocated in a user arena chunk. It</code></span>
<span class="codeline" id="line-1295"><code>// sets up the type metadata for the value with type typ allocated at address ptr.</code></span>
<span class="codeline" id="line-1296"><code>// base is the base address of the arena chunk.</code></span>
<span class="codeline" id="line-1297"><code>func userArenaHeapBitsSetType(typ *_type, ptr unsafe.Pointer, s *mspan) {</code></span>
<span class="codeline" id="line-1298"><code>	base := s.base()</code></span>
<span class="codeline" id="line-1299"><code>	h := s.writeUserArenaHeapBits(uintptr(ptr))</code></span>
<span class="codeline" id="line-1300"><code></code></span>
<span class="codeline" id="line-1301"><code>	p := typ.GCData // start of 1-bit pointer mask (or GC program)</code></span>
<span class="codeline" id="line-1302"><code>	var gcProgBits uintptr</code></span>
<span class="codeline" id="line-1303"><code>	if typ.Kind_&amp;kindGCProg != 0 {</code></span>
<span class="codeline" id="line-1304"><code>		// Expand gc program, using the object itself for storage.</code></span>
<span class="codeline" id="line-1305"><code>		gcProgBits = runGCProg(addb(p, 4), (*byte)(ptr))</code></span>
<span class="codeline" id="line-1306"><code>		p = (*byte)(ptr)</code></span>
<span class="codeline" id="line-1307"><code>	}</code></span>
<span class="codeline" id="line-1308"><code>	nb := typ.PtrBytes / goarch.PtrSize</code></span>
<span class="codeline" id="line-1309"><code></code></span>
<span class="codeline" id="line-1310"><code>	for i := uintptr(0); i &lt; nb; i += ptrBits {</code></span>
<span class="codeline" id="line-1311"><code>		k := nb - i</code></span>
<span class="codeline" id="line-1312"><code>		if k &gt; ptrBits {</code></span>
<span class="codeline" id="line-1313"><code>			k = ptrBits</code></span>
<span class="codeline" id="line-1314"><code>		}</code></span>
<span class="codeline" id="line-1315"><code>		// N.B. On big endian platforms we byte swap the data that we</code></span>
<span class="codeline" id="line-1316"><code>		// read from GCData, which is always stored in little-endian order</code></span>
<span class="codeline" id="line-1317"><code>		// by the compiler. writeUserArenaHeapBits handles data in</code></span>
<span class="codeline" id="line-1318"><code>		// a platform-ordered way for efficiency, but stores back the</code></span>
<span class="codeline" id="line-1319"><code>		// data in little endian order, since we expose the bitmap through</code></span>
<span class="codeline" id="line-1320"><code>		// a dummy type.</code></span>
<span class="codeline" id="line-1321"><code>		h = h.write(s, readUintptr(addb(p, i/8)), k)</code></span>
<span class="codeline" id="line-1322"><code>	}</code></span>
<span class="codeline" id="line-1323"><code>	// Note: we call pad here to ensure we emit explicit 0 bits</code></span>
<span class="codeline" id="line-1324"><code>	// for the pointerless tail of the object. This ensures that</code></span>
<span class="codeline" id="line-1325"><code>	// there's only a single noMorePtrs mark for the next object</code></span>
<span class="codeline" id="line-1326"><code>	// to clear. We don't need to do this to clear stale noMorePtrs</code></span>
<span class="codeline" id="line-1327"><code>	// markers from previous uses because arena chunk pointer bitmaps</code></span>
<span class="codeline" id="line-1328"><code>	// are always fully cleared when reused.</code></span>
<span class="codeline" id="line-1329"><code>	h = h.pad(s, typ.Size_-typ.PtrBytes)</code></span>
<span class="codeline" id="line-1330"><code>	h.flush(s, uintptr(ptr), typ.Size_)</code></span>
<span class="codeline" id="line-1331"><code></code></span>
<span class="codeline" id="line-1332"><code>	if typ.Kind_&amp;kindGCProg != 0 {</code></span>
<span class="codeline" id="line-1333"><code>		// Zero out temporary ptrmask buffer inside object.</code></span>
<span class="codeline" id="line-1334"><code>		memclrNoHeapPointers(ptr, (gcProgBits+7)/8)</code></span>
<span class="codeline" id="line-1335"><code>	}</code></span>
<span class="codeline" id="line-1336"><code></code></span>
<span class="codeline" id="line-1337"><code>	// Update the PtrBytes value in the type information. After this</code></span>
<span class="codeline" id="line-1338"><code>	// point, the GC will observe the new bitmap.</code></span>
<span class="codeline" id="line-1339"><code>	s.largeType.PtrBytes = uintptr(ptr) - base + typ.PtrBytes</code></span>
<span class="codeline" id="line-1340"><code></code></span>
<span class="codeline" id="line-1341"><code>	// Double-check that the bitmap was written out correctly.</code></span>
<span class="codeline" id="line-1342"><code>	const doubleCheck = false</code></span>
<span class="codeline" id="line-1343"><code>	if doubleCheck {</code></span>
<span class="codeline" id="line-1344"><code>		doubleCheckHeapPointersInterior(uintptr(ptr), uintptr(ptr), typ.Size_, typ.Size_, typ, &amp;s.largeType, s)</code></span>
<span class="codeline" id="line-1345"><code>	}</code></span>
<span class="codeline" id="line-1346"><code>}</code></span>
<span class="codeline" id="line-1347"><code></code></span>
<span class="codeline" id="line-1348"><code>// For !goexperiment.AllocHeaders, to pass TestIntendedInlining.</code></span>
<span class="codeline" id="line-1349"><code>func writeHeapBitsForAddr() {</code></span>
<span class="codeline" id="line-1350"><code>	panic("not implemented")</code></span>
<span class="codeline" id="line-1351"><code>}</code></span>
<span class="codeline" id="line-1352"><code></code></span>
<span class="codeline" id="line-1353"><code>// For !goexperiment.AllocHeaders.</code></span>
<span class="codeline" id="line-1354"><code>type heapBits struct {</code></span>
<span class="codeline" id="line-1355"><code>}</code></span>
<span class="codeline" id="line-1356"><code></code></span>
<span class="codeline" id="line-1357"><code>// For !goexperiment.AllocHeaders.</code></span>
<span class="codeline" id="line-1358"><code>//</code></span>
<span class="codeline" id="line-1359"><code>//go:nosplit</code></span>
<span class="codeline" id="line-1360"><code>func heapBitsForAddr(addr, size uintptr) heapBits {</code></span>
<span class="codeline" id="line-1361"><code>	panic("not implemented")</code></span>
<span class="codeline" id="line-1362"><code>}</code></span>
<span class="codeline" id="line-1363"><code></code></span>
<span class="codeline" id="line-1364"><code>// For !goexperiment.AllocHeaders.</code></span>
<span class="codeline" id="line-1365"><code>//</code></span>
<span class="codeline" id="line-1366"><code>//go:nosplit</code></span>
<span class="codeline" id="line-1367"><code>func (h heapBits) next() (heapBits, uintptr) {</code></span>
<span class="codeline" id="line-1368"><code>	panic("not implemented")</code></span>
<span class="codeline" id="line-1369"><code>}</code></span>
<span class="codeline" id="line-1370"><code></code></span>
<span class="codeline" id="line-1371"><code>// For !goexperiment.AllocHeaders.</code></span>
<span class="codeline" id="line-1372"><code>//</code></span>
<span class="codeline" id="line-1373"><code>//go:nosplit</code></span>
<span class="codeline" id="line-1374"><code>func (h heapBits) nextFast() (heapBits, uintptr) {</code></span>
<span class="codeline" id="line-1375"><code>	panic("not implemented")</code></span>
<span class="codeline" id="line-1376"><code>}</code></span>
</pre><pre id="footer">
<table><tr><td><img src="../../png/go101-twitter.png"></td>
<td>The pages are generated with <a href="https://go101.org/apps-and-libs/golds.html"><b>Golds</b></a> <i>v0.6.8</i>. (GOOS=linux GOARCH=amd64)
<b>Golds</b> is a <a href="https://go101.org">Go 101</a> project developed by <a href="https://tapirgames.com">Tapir Liu</a>.
PR and bug reports are welcome and can be submitted to <a href="https://github.com/go101/golds">the issue list</a>.
Please follow <a href="https://twitter.com/go100and1">@Go100and1</a> (reachable from the left QR code) to get the latest news of <b>Golds</b>.</td></tr></table></pre>